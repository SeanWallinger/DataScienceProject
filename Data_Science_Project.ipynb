{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeanWallinger/DataScienceProject/blob/main/Data_Science_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0riwwMKCn9_q"
      },
      "source": [
        "#Mental Health Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmiUqMl-oEdZ"
      },
      "source": [
        "\n",
        "\n",
        "*   Sean Wallinger\n",
        "*   Math 5364 Data Science 1\n",
        "*   Tarleton State University\n",
        "*   Spring 2023\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-qOsJ3ZbYvJ"
      },
      "source": [
        "DISCLAMER: This is NOT a diagnosis! These findings are based on common symptoms of mental issues. If you are concerned about your mental health seek professional medical help."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONfsEzjQxddX"
      },
      "source": [
        "##Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2nA6MY3xgwg"
      },
      "source": [
        "The task of this project To create a model that can aid in the early dectetion of serious mental issues using data from the data set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY_VYpW2oL6j"
      },
      "source": [
        "##Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdVMq3sMAV_P"
      },
      "source": [
        "For many years, Mental issues and Anxiety has effected people and caused many problems. The field of pycology has worked very hard to try to understand, identify sympotoms, and try to get patients the help they need before it is too late. But, identifing these big mental issues with simple symptoms is a very challenging task. Now the question can be asked, can past cases help future ones? Can past patterns and symptoms possibly help identify current patients who may not even know if they have an issue?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4khyxgT0P3p4"
      },
      "source": [
        "###Depression Anxiety Stress Scales (DASS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxOM3UnsQhl4"
      },
      "source": [
        "The Psychology Foundation of Australia created the Depression Anxiety Stress Scales (DASS) and hosted the questionnaire on a public website in an effort to help educate the public on Depression, Anxiety, and Stress.\n",
        "\n",
        "The DASS is comprised of 42 questions which are divided into three sets of 14 questions which are related to the topics of Depression, Anxiety, and Stress. These questions have four possible responses which relate to a possible score as seen below:\n",
        "\n",
        "    Did not apply to me at all ---> 0\n",
        "    Applied to me to some degree, or some of the time ---> 1\n",
        "    Applied to me to a considerable degree, or a good part of time ---> 2\n",
        "    Applied to me very much, or most of the time ---- 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s8-xWnQULif"
      },
      "source": [
        "####Question Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXfI9Z0cUYu7"
      },
      "source": [
        "![demo1.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pp71514hoxZ"
      },
      "source": [
        "###The Ten-Item Personality Test (TIPI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRTVOEDphzN0"
      },
      "source": [
        "To help get an idea of the personality of each entry, a Ten-Item Personality Test was administered and resposes where measured. The TIPT asks ten questions about a persons behavor and the User responds on a 7 point scale as show below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBAbASZYjOxe"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuaegifQjW9q"
      },
      "source": [
        "Two of the Ten questions relate to one of the big Five personality traits, the average of these finds a person's mesure in each of these personalities. The five big personalities are Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmv53LFEljNK"
      },
      "source": [
        "<img src = https://saylordotorg.github.io/text_principles-of-management-v1.1/section_06/2ca4a3e8a5ffc2a3ff954f79a1475071.jpg width = \"575\" height = \"383\" >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9mgS95IU_pY"
      },
      "source": [
        "###Scoring Scales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NLXNl-gVEKP"
      },
      "source": [
        "The Score for the DASS 42 questionair is derived by summing up all the questions that relate to the relative topic. The total score is an indicator of the severity of the self reported symptoms that relate to mental issues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rbeXnOIfp8T"
      },
      "source": [
        "####Scoring Scale of the DASS 42 Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwjFAv1MfwNo"
      },
      "source": [
        "![Screenshot 2023-03-01 124519.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB6OhOPkvWI9"
      },
      "source": [
        "####Scoring of the TIPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfjK9WvyvdZt"
      },
      "source": [
        "The score of the person's measure of the big five personalities are determined by finding the two answers that relate to the respective personality. Add one score to the reversed score of the other. The average of these two score is the metric of that person possessing such a personality trait."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY02y715otK0"
      },
      "source": [
        "###Goal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI6xawE-BcjD"
      },
      "source": [
        "The Goal of this project is to Predict the severity of a person's Depression, Anxiety, and Stress Target Variables using personal information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jXaRgKgokQI"
      },
      "source": [
        "##Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiykW2H1orUK"
      },
      "source": [
        "###[Psychology Foundation of Australia](http://www.psychologyfoundation.org.au/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ho9H7ccpTnL"
      },
      "source": [
        "[\"The Psychology Foundation of Australia is a grouping of research-oriented schools of Psychology formed to defend rigorous academic and scientific standards in the teaching, research and training in the discipline of Psychology and its professional practice within Australia.\"](http://www.psychologyfoundation.org.au/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtmW2flopfSY"
      },
      "source": [
        "####[Depression Anxiety Stress Scales Responses](https://www.kaggle.com/datasets/lucasgreenwell/depression-anxiety-stress-scales-responses?select=codebook.txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq-bj39hpu67"
      },
      "source": [
        "- Collected March 7th, 2023 via direct download of csv file.\n",
        "- Data was collected with an on-line wersion of the Depression Anxiety Stress Scales (DASS).\n",
        "- The survey was open to anyone and people were motivated to take it to get personalized results. At the end of the test they also were given the option to complete a short research survey. This datatset comes from those who agreed to complete the research survey and answered yes to the question \"Have you given accurate answers and may they be used for research?\" at the end.\n",
        "- This data was collected 2017 - 2019.\n",
        "- Important Features:\n",
        "    - Q(number)A (int): The User's answer to question (number).\n",
        "    - Country (str): ISO country code of where the user connected from.\n",
        "    - TIPI(number) (int): Answer to Ten Item Personality inventory Question (number).\n",
        "    - Education (int): The highest education level the User has completed.\n",
        "    - Urban (int): The Type of area the User lived in as a child.\n",
        "    - Gender (int): The Gender of the User.\n",
        "    - Age (int): The Age of the User.\n",
        "    - Hand (int): The hand that the User writes with.\n",
        "    - Religon (int): What religon the User practices.\n",
        "    - Orientation (int): The Sexual orientation of the User.\n",
        "    - Race (int): The Race of the User.\n",
        "    - Married (int): The Marital status of the User.\n",
        "    - Family Size (int): The amount of childeren the User's mother had.\n",
        "\n",
        "- [More Information on the DASS Questionnaire](http://www2.psy.unsw.edu.au/dass/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8LjDIfXb-D6"
      },
      "source": [
        "###Data Wrangling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdibTo4ScApT"
      },
      "source": [
        "Here are the major data wrangling challenges and solutions.\n",
        "\n",
        "1.   The Data set has entries from many international users randomly taken across the globe.\n",
        "\n",
        "  *   The only rows grabbed from the data set stored in Google's BigQuery is the rows that have the 'US' string in the Country feature since it is easier to gain censis data to improve the model.\n",
        "  *   An International look will be contemplated during the project.\n",
        "\n",
        "2.   All of the answers from the Questionnaire (i.e. 'q1a', 'q2a', ect.) is stored alternatively to common computer science format.\n",
        "\n",
        "  *   Shifted the threshold of the stored answers to match the standard range of zero to four.\n",
        "\n",
        "3.   The Data set stores the ansers to each question in their own spearate column.\n",
        "\n",
        "  *   Added all data from columns 'Q3A', 'Q5A', 'Q10A', 'Q13A', 'Q16A', 'Q17A', 'Q21A', 'Q24A', 'Q26A', 'Q31A', 'Q34A', 'Q37A', 'Q38A', and 'Q42A'. A new Feature column was created to store this score as the severty of the user's Depression. This Severty scal is as such: 0 for Normal (Score: 0-9), 1 for mild (score: 10-13), 2 for Moderate (Score: 14-20), 3 for Severe (score: 21-27), and 4 for Extremely Severe (Score: 28+). \n",
        "\n",
        "  *   Added all data from columns 'Q2A', 'Q4A', 'Q7A', 'Q9A', 'Q15A', 'Q19A', 'Q20A', 'Q23A', 'Q25A', 'Q28A', 'Q30A', 'Q36A', 'Q40A', and 'Q41A'. A new Feature column was created to store this score as the severty of the user's Anxiety. This Severty scal is as such: 0 for Normal (Score: 0-7), 1 for mild (score: 8-9), 2 for Moderate (Score: 10-14), 3 for Severe (score: 15-19), and 4 for Extremely Severe (Score: 20+).\n",
        "\n",
        "  *   Added all data from columns 'Q1A', 'Q6A', 'Q8A', 'Q11A', 'Q12A', 'Q14A', 'Q18A', 'Q22A', 'Q27A', 'Q29A', 'Q32A', 'Q33A', 'Q35A', and 'Q39A'. A new Feature column was created to store this score as the severty of the user's Stress. This Severty scal is as such: 0 for Normal (Score: 0-14), 1 for mild (score: 15-18), 2 for Moderate (Score: 19-25), 3 for Severe (score: 26-33), and 4 for Extremely Severe (Score: 34+).\n",
        "\n",
        "4.   The Data set also consists of the results from a Ten Item Personality Test that was administered with the online questionnaire. \n",
        "\n",
        "  *   Each entry relates to one of five categories. Each category has two questions associated with it, one for and one against. The against question's score is reversed (i.e. if the input is 2 then swap it to 6) and take the average of these two answers to get the category score.\n",
        "\n",
        "5.   The dataset consists of alot of data with general categorical features.\n",
        "\n",
        "  *   Took the Data stored in these catigorical features and created a new column for each catigory to make it binary.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WED6CShzWx_E"
      },
      "source": [
        "#Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TqBYxIw5EH4C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb2bd21c-af4b-4219-ed57-158a0858bbed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for helpers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.5.3, but you have pandas 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install -q 'git+https://github.com/drscook/helpers'\n",
        "! pip install -q --upgrade pandas scikit-learn # pandas 2.0 just released on April 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IzzDlsw5ETqA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36d10a55-bd3f-4fef-acdc-d0c7925bc758"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 12.9 s (2023-04-22T22:52:41/2023-04-22T22:52:54)</pre>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%reload_ext autotime\n",
        "from helpers.common_imports import *\n",
        "from helpers import utilities as ut\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, BaggingClassifier, BaggingRegressor, HistGradientBoostingRegressor, HistGradientBoostingClassifier\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, ConfusionMatrixDisplay, confusion_matrix, RocCurveDisplay\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "rEAu9GuAEhGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9184068-a7b1-456d-f1f7-5643399ef456"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 2.68 s (2023-04-23T01:47:21/2023-04-23T01:47:24)</pre>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Pull from Big Query.\n",
        "bq = ut.BigQuery()\n",
        "tbl = f\"tarletondatascience2022.wallinger.Depression_Anxiety_Stress_Scales\"\n",
        "qry = f\"\"\"\n",
        "select\n",
        "    *\n",
        "from\n",
        "    {tbl}\n",
        "where\n",
        "    country = 'US'\n",
        "\"\"\"\n",
        "\n",
        "df = bq.qry_to_df(qry)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Global Variables.\n",
        "randnum = 500 #Setting a random number to get similar results.\n",
        "Holdout_size = 0.3 #Sets the Holdout portion.\n",
        "C = np.linspace(0.1,1,num=10) #Creates a Cost Varaible for the SVC Models.\n",
        "\n",
        "#List Containing Class names for the verification of the Classification Models.\n",
        "DepClassNames =  ['No Depression', 'Mild Depression', 'Moderate Depression', 'Severe Depression', 'Extremely Severe Depression']\n",
        "AnxClassNames =  ['No Anxiety', 'Mild Anxiety', 'Moderate Anxiety', 'Severe Anxiety', 'Extremely Severe Anxiety']\n",
        "StsClassNames =  ['No Stress', 'Mild Stress', 'Moderate Stress', 'Severe Stress', 'Extremely Severe Stress']"
      ],
      "metadata": {
        "id": "Oruq0u2zufPd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95aa4e9a-20b2-4f46-a9bc-10019a0752f0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 1.71 ms (2023-04-23T01:47:24/2023-04-23T01:47:24)</pre>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Checking the Data"
      ],
      "metadata": {
        "id": "gqgMOLDpKHFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset is fairly good right away. No missing values in all features and targets, Large row count, and besides some minor formatting issues. Only one typo was found but since this may effect the normalization range, I chaged to more likely input. Also found some outliers in the faimlysize but unsure if I would be removing too much variance."
      ],
      "metadata": {
        "id": "FMIUfamV1YL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fixes the age error.\n",
        "WorngAge = 117\n",
        "CorrectAge = 17\n",
        "df.at[4741, 'age'] = CorrectAge\n",
        "\n",
        "#Verifies that the fix is indeed in place.\n",
        "print(df.loc[df['age'] == WorngAge, 'age'])\n",
        "\n",
        "print(df.loc[df['familysize'] > 20, 'familysize'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "oPY6K9HC2uG0",
        "outputId": "6daa3213-5c2f-4d7a-fa71-6c97503fffb7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 6.69 ms (2023-04-23T01:47:25/2023-04-23T01:47:25)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series([], Name: age, dtype: Int64)\n",
            "index\n",
            "6765     62\n",
            "8052    133\n",
            "Name: familysize, dtype: Int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ut.pprint(df)"
      ],
      "metadata": {
        "id": "u8_HbjgwKMCc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "367c95e7-baed-4252-c4d8-286810960fb9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 483 ms (2023-04-22T22:53:14/2023-04-22T22:53:14)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       q1a  q1i    q1e  q2a  q2i    q2e  q3a  q3i    q3e  q4a  q4i   q4e  q5a   \n",
              "index                                                                           \n",
              "0        1   18   6116    1   28   3193    2    2  12542    1    8  6150    3  \\\n",
              "1        1   10   2901    1    1   9036    1   22   3775    1   34  2027    1   \n",
              "2        3    5   6729    2    4   4793    2   20   3328    1   16  2199    3   \n",
              "3        1    9   2236    1   10   1437    2    7   2570    1   17  2188    1   \n",
              "4        1   35   3404    2   28  10935    1    5   3593    1   13  5086    1   \n",
              "...    ...  ...    ...  ...  ...    ...  ...  ...    ...  ...  ...   ...  ...   \n",
              "8202     4   17   3069    4    6   3561    4   25   2200    3   21  3045    4   \n",
              "8203     3   30   3626    1   38   4161    2   27   2640    3    2  7369    4   \n",
              "8204     4   16   2000    2   10   2055    4   22   2229    3    9  3527    4   \n",
              "8205     4   38   2350    2   29   2316    4   20   2087    4   30  2614    4   \n",
              "8206     3   32  28897    4    4   3025    2   30   3248    2   16  8048    2   \n",
              "\n",
              "       q5i   q5e  q6a  q6i    q6e  q7a  q7i   q7e  q8a  q8i   q8e  q9a  q9i   \n",
              "index                                                                         \n",
              "0       40  6428    1    4  17001    1   33  2944    3    7  8626    3   14  \\\n",
              "1       38  2714    1    3   3626    1   11  4496    1   27  3453    1   41   \n",
              "2       22  2513    1   21   2220    1   13  2489    2   32  2570    1    8   \n",
              "3       27  3372    1    2   1975    1    6  1579    1   37  1736    1   26   \n",
              "4       17  2810    1   10   3677    1   29  4919    1    6  3288    1   38   \n",
              "...    ...   ...  ...  ...    ...  ...  ...   ...  ...  ...   ...  ...  ...   \n",
              "8202     1  8671    4   30   2186    4   32  1527    4    4  2236    4   26   \n",
              "8203    12  2607    4   15   2122    4   19  2473    3   32  1538    4   37   \n",
              "8204     6  1633    4   24   1032    2   21  3567    4    4  2608    4   31   \n",
              "8205    19  1320    4   35   8479    4   36  1443    4   21  1320    4    8   \n",
              "8206     8  3559    4   34   2219    4    5  4553    2   21  1890    1   36   \n",
              "\n",
              "         q9e  q10a  q10i  q10e  q11a  q11i   q11e  q12a  q12i  q12e  q13a   \n",
              "index                                                                       \n",
              "0       9639     2    20  6175     1    34   6008     2    21  9267     1  \\\n",
              "1       4619     1    21  2540     1    20   2946     1     6  3508     1   \n",
              "2       5790     2    18  4348     1     1   5951     1    26  1973     1   \n",
              "3      11058     2     8  3389     1    38   2105     1    23  2218     1   \n",
              "4       8824     1    31  5750     1    21   2475     1    37  2422     1   \n",
              "...      ...   ...   ...   ...   ...   ...    ...   ...   ...   ...   ...   \n",
              "8202    1265     4    20  2232     4    34   1676     4    40  1716     4   \n",
              "8203    4779     2    28  2741     4    13   2389     3    34  2690     4   \n",
              "8204    2936     4    19  1848     4    12   2448     2     8  4936     4   \n",
              "8205    2862     4    28  1488     4     1  12252     4    37  1481     4   \n",
              "8206    4561     3    11  4071     3    23   2909     3    17  5179     4   \n",
              "\n",
              "       q13i  q13e  q14a  q14i   q14e  q15a  q15i  q15e  q16a  q16i  q16e   \n",
              "index                                                                      \n",
              "0        41  5290     3     1  25694     2     9  7634     4    37  8513  \\\n",
              "1        14  1727     1    31   4508     1     4  2490     1     5  3725   \n",
              "2        11  2679     4    33   3425     1    23  1931     3    28  4472   \n",
              "3        19  1803     1    31   3058     2    29  4186     3     5  2184   \n",
              "4        36  1638     1    24  15928     1    12  2770     1    26  4719   \n",
              "...     ...   ...   ...   ...    ...   ...   ...   ...   ...   ...   ...   \n",
              "8202     16  2553     4    39   1797     4    33  1585     4    23  3475   \n",
              "8203     18  1320     4    14   3376     3     5  1621     2    29  2038   \n",
              "8204      3  1423     4    40   3063     4    33  1103     4    11  2240   \n",
              "8205     10  1291     4    12   2200     4    33  3329     4    23  1575   \n",
              "8206     14  2190     2    28  52923     1    41  2126     2    18  3341   \n",
              "\n",
              "       q17a  q17i  q17e  q18a  q18i  q18e  q19a  q19i   q19e  q20a  q20i   \n",
              "index                                                                      \n",
              "0         2    25  9078     1    15  4381     1    23   6647     2    36  \\\n",
              "1         1    28  4826     1    17  2425     1    13   3002     1    23   \n",
              "2         1    24  1450     2    40  2006     1    25   3613     1    19   \n",
              "3         1    11  3906     1    14  2010     1    35   3128     1    30   \n",
              "4         1    39  3639     1    32  1745     1    11   8400     1    23   \n",
              "...     ...   ...   ...   ...   ...   ...   ...   ...    ...   ...   ...   \n",
              "8202      4    14  2722     4    18  1785     3    29   4253     4    11   \n",
              "8203      4    40  2406     1    26  3810     3     9   3910     3    17   \n",
              "8204      4    27  1832     4    23  1383     2    37   3498     4     7   \n",
              "8205      4    18  1286     3     6  2491     2    34   3308     4    16   \n",
              "8206      2    24  3949     4    29  4455     3     2  19120     3     7   \n",
              "\n",
              "       q20e  q21a  q21i  q21e  q22a  q22i  q22e  q23a  q23i  q23e  q24a  q24i   \n",
              "index                                                                           \n",
              "0      6250     1    39  3842     1    16  7876     1    27  3124     2    12  \\\n",
              "1      2371     1    37  4058     1    25  2721     1     7  2511     1    33   \n",
              "2      1166     1    15  3214     1    10  4843     1    27  1216     3    41   \n",
              "3      2375     2    42  1957     1    13  1567     1    24  1334     3     4   \n",
              "4      2408     1    30  3548     1    42  4149     1    20  3043     1    41   \n",
              "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
              "8202   2077     4     8  1918     4    15  1533     3    22  2939     4    37   \n",
              "8203   2106     3    41  3241     3    21  2975     2    25  1722     2     3   \n",
              "8204   1760     4    34  1438     4    38  1422     2    15  2296     4    29   \n",
              "8205   1336     4    13  1555     4    15  1270     1     2  3946     4    26   \n",
              "8206   4429     1    39  3372     3    31  3409     1     9  2538     1    10   \n",
              "\n",
              "       q24e  q25a  q25i   q25e  q26a  q26i  q26e  q27a  q27i  q27e  q28a   \n",
              "index                                                                      \n",
              "0      6836     1    31  12063     1     3  9264     1    35  3957     1  \\\n",
              "1      2981     1     9   4554     1    18  1894     1    40  1541     1   \n",
              "2      4086     2    37   5170     1    35  1703     2     9  2482     1   \n",
              "3      2903     1    25   2473     1    41  1397     1    20  2119     1   \n",
              "4      3698     1    27  27429     1    15  2660     1    19  2621     1   \n",
              "...     ...   ...   ...    ...   ...   ...   ...   ...   ...   ...   ...   \n",
              "8202   2699     4     2   8376     4    10  1452     4    35  1325     4   \n",
              "8203   2456     2     6   3008     4    35  2506     2    22  2991     3   \n",
              "8204   1289     4    32   2384     4     5  2207     4    14  1632     4   \n",
              "8205   1604     4    27   6550     4    41  1244     4    39  1256     4   \n",
              "8206   2541     4    35   8110     2    25  2701     4     6  2408     3   \n",
              "\n",
              "       q28i  q28e  q29a  q29i   q29e  q30a  q30i   q30e  q31a  q31i   q31e   \n",
              "index                                                                        \n",
              "0        42  2537     3    17  10880     2     5   8462     2    32   5615  \\\n",
              "1        12  3354     1    29   3129     1    24   5256     1     2   5345   \n",
              "2        29  1741     1    14   2681     1    12   2779     3    38   2302   \n",
              "3         1  4983     1    15   3193     1    12   2454     1    18   6983   \n",
              "4        22  2219     1     7   2827     1     4   4980     1    25   2623   \n",
              "...     ...   ...   ...   ...    ...   ...   ...    ...   ...   ...    ...   \n",
              "8202      9  3080     4    13   2771     4    31   2336     4    41   2938   \n",
              "8203      4  2173     4     8   2574     4    31   6601     2    23   2957   \n",
              "8204     36  1544     4    20   2351     4    35   1824     4     1   5042   \n",
              "8205     24  1223     4    40   1841     3     7   3922     4    31   2839   \n",
              "8206     37  2909     4    42   4100     2    33  13153     2    13  19343   \n",
              "\n",
              "       q32a  q32i   q32e  q33a  q33i  q33e  q34a  q34i  q34e  q35a  q35i   \n",
              "index                                                                      \n",
              "0         1    30  11412     4     6  5112     1    29  3070     3    10  \\\n",
              "1         1    36   3058     1    39  1690     1    30  1686     1    26   \n",
              "2         2    30   3895     1    36  1313     1    34  1426     4    31   \n",
              "3         1     3   3281     1    40  2984     1    34  1676     1    22   \n",
              "4         1     2  11105     1    33  2245     1    18  5499     1    16   \n",
              "...     ...   ...    ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
              "8202      4    19   3676     4    42  1717     4    24  1301     4    28   \n",
              "8203      4    16   4044     4     7  2222     3     1  4782     3    11   \n",
              "8204      4    39   1528     4    26  1368     4    17  1344     4    41   \n",
              "8205      4    25   2615     4    42  1342     4    11  1194     2     9   \n",
              "8206      3    22   5189     3    27  3088     4    15  2900     2    12   \n",
              "\n",
              "        q35e  q36a  q36i  q36e  q37a  q37i   q37e  q38a  q38i  q38e  q39a   \n",
              "index                                                                       \n",
              "0      13377     2    38  4506     2    24  17227     2    13  7844     1  \\\n",
              "1       4135     1    42  1852     1    19   4181     1    15  1898     1   \n",
              "2       3803     1     3  2430     1    39   2035     2     7  2754     3   \n",
              "3       5516     1    36  1483     2    33   3556     2    16  2299     2   \n",
              "4       6972     1     9  1761     1     8   8120     1     1  6261     1   \n",
              "...      ...   ...   ...   ...   ...   ...    ...   ...   ...   ...   ...   \n",
              "8202    4973     4    12  1492     4    27   2865     4     7  1791     4   \n",
              "8203    6651     2    39  1604     3    33   3008     4    20  2206     3   \n",
              "8204    1889     4     2  4773     4    30   2886     4    28  1592     4   \n",
              "8205    5597     4    22  1214     4     4   1743     4    32  1833     4   \n",
              "8206   23056     1    19  1677     2     1  15366     1    26  2718     4   \n",
              "\n",
              "       q39i   q39e  q40a  q40i  q40e  q41a  q41i  q41e  q42a  q42i   q42e   \n",
              "index                                                                       \n",
              "0        26  20253     1    22  8528     1    11  4370     2    19  10310  \\\n",
              "1        32   1389     1    35  4266     1    16  1534     1     8   3449   \n",
              "2         6   2830     1    42  2357     1    17  3662     4     2   3372   \n",
              "3        32   2794     1    39  2537     1    28  1524     1    21   2944   \n",
              "4        34   2259     1     3  3951     1    14  2576     1    40  11750   \n",
              "...     ...    ...   ...   ...   ...   ...   ...   ...   ...   ...    ...   \n",
              "8202      5   1858     4     3  6011     4    38  1735     4    36   2849   \n",
              "8203     24   2240     4    42  2424     4    36  2106     3    10   4078   \n",
              "8204     42   1208     4    13  2679     4    25  1320     4    18   1920   \n",
              "8205     14   1371     4     3  3110     4     5  3029     4    17   4222   \n",
              "8206     40   4331     4     3  3769     2    20  4261     1    38   4709   \n",
              "\n",
              "      country  source  introelapse  testelapse  surveyelapse  tipi1  tipi2   \n",
              "index                                                                        \n",
              "0          US       2            4         349           213      2      1  \\\n",
              "1          US       2            2         143           228      3      5   \n",
              "2          US       2           73         128            89      2      7   \n",
              "3          US       0           42         121           171      3      3   \n",
              "4          US       2            5         221           183      7      4   \n",
              "...       ...     ...          ...         ...           ...    ...    ...   \n",
              "8202       US       2            2         115            78      1      5   \n",
              "8203       US       0           50         128           144      2      5   \n",
              "8204       US       1            4         120           221      3      6   \n",
              "8205       US       2           22         116            86      2      4   \n",
              "8206       US       2            2         300           234      6      5   \n",
              "\n",
              "       tipi3  tipi4  tipi5  tipi6  tipi7  tipi8  tipi9  tipi10  vcl1  vcl2   \n",
              "index                                                                        \n",
              "0          6      1      7      7      7      2      6       7     1     1  \\\n",
              "1          6      1      6      5      3      2      7       2     1     1   \n",
              "2          7      1      6      5      4      7      6       2     1     1   \n",
              "3          5      1      5      5      5      5      6       5     1     1   \n",
              "4          6      1      6      3      4      2      6       1     1     0   \n",
              "...      ...    ...    ...    ...    ...    ...    ...     ...   ...   ...   \n",
              "8202       1      7      4      7      6      7      4       1     1     1   \n",
              "8203       6      7      5      5      5      4      1       4     1     1   \n",
              "8204       6      7      2      6      4      2      2       1     1     1   \n",
              "8205       1      7      2      4      2      6      1       5     1     1   \n",
              "8206       4      5      6      3      5      2      5       7     1     1   \n",
              "\n",
              "       vcl3  vcl4  vcl5  vcl6  vcl7  vcl8  vcl9  vcl10  vcl11  vcl12  vcl13   \n",
              "index                                                                         \n",
              "0         0     1     1     0     0     0     0      1      0      0      0  \\\n",
              "1         1     1     1     0     1     1     0      1      1      1      1   \n",
              "2         1     1     1     0     0     0     0      1      0      0      1   \n",
              "3         0     1     1     0     0     0     0      1      0      0      0   \n",
              "4         0     1     1     0     0     0     0      1      0      0      1   \n",
              "...     ...   ...   ...   ...   ...   ...   ...    ...    ...    ...    ...   \n",
              "8202      0     1     1     0     0     0     0      1      0      0      1   \n",
              "8203      1     1     1     0     0     0     0      1      0      0      1   \n",
              "8204      1     1     1     0     0     0     0      1      1      0      1   \n",
              "8205      0     1     1     0     0     0     0      1      0      0      0   \n",
              "8206      0     1     1     0     0     0     0      1      0      0      1   \n",
              "\n",
              "       vcl14  vcl15  vcl16  education  urban  gender  engnat  age  screensize   \n",
              "index                                                                           \n",
              "0          0      1      1          2      3       2       2   20           2  \\\n",
              "1          1      1      1          3      2       1       1   34           2   \n",
              "2          1      1      1          2      1       1       1   19           2   \n",
              "3          1      1      1          2      3       2       1   16           1   \n",
              "4          1      1      1          2      2       1       1   18           2   \n",
              "...      ...    ...    ...        ...    ...     ...     ...  ...         ...   \n",
              "8202       1      1      1          3      3       2       1   22           2   \n",
              "8203       1      1      1          1      3       3       1   18           2   \n",
              "8204       1      1      1          4      2       2       1   46           2   \n",
              "8205       0      1      1          1      3       2       1   14           2   \n",
              "8206       1      1      1          1      2       2       1   16           2   \n",
              "\n",
              "       uniquenetworklocation  hand  religion  orientation  race  voted   \n",
              "index                                                                    \n",
              "0                          1     1         4            1    70      2  \\\n",
              "1                          1     1         1            1    60      1   \n",
              "2                          1     3         2            1    60      2   \n",
              "3                          1     1         1            5    70      2   \n",
              "4                          2     1         7            1    30      2   \n",
              "...                      ...   ...       ...          ...   ...    ...   \n",
              "8202                       1     1         7            1    10      1   \n",
              "8203                       1     1         2            4    70      2   \n",
              "8204                       1     1         4            1    60      1   \n",
              "8205                       1     1         1            5    60      2   \n",
              "8206                       1     1         1            1    70      2   \n",
              "\n",
              "       married  familysize                              major  \n",
              "index                                                          \n",
              "0            1           4                               <NA>  \n",
              "1            3           2  Biology and Philosophy dual major  \n",
              "2            1           1                   Computer Science  \n",
              "3            1           3                               <NA>  \n",
              "4            1           2                               <NA>  \n",
              "...        ...         ...                                ...  \n",
              "8202         1           3                            English  \n",
              "8203         1           2                               <NA>  \n",
              "8204         2           6                          Marketing  \n",
              "8205         1           3                               <NA>  \n",
              "8206         1           3                               <NA>  \n",
              "\n",
              "[8207 rows x 172 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4259e723-4b1b-4320-b7de-1930710bbef6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q1a</th>\n",
              "      <th>q1i</th>\n",
              "      <th>q1e</th>\n",
              "      <th>q2a</th>\n",
              "      <th>q2i</th>\n",
              "      <th>q2e</th>\n",
              "      <th>q3a</th>\n",
              "      <th>q3i</th>\n",
              "      <th>q3e</th>\n",
              "      <th>q4a</th>\n",
              "      <th>q4i</th>\n",
              "      <th>q4e</th>\n",
              "      <th>q5a</th>\n",
              "      <th>q5i</th>\n",
              "      <th>q5e</th>\n",
              "      <th>q6a</th>\n",
              "      <th>q6i</th>\n",
              "      <th>q6e</th>\n",
              "      <th>q7a</th>\n",
              "      <th>q7i</th>\n",
              "      <th>q7e</th>\n",
              "      <th>q8a</th>\n",
              "      <th>q8i</th>\n",
              "      <th>q8e</th>\n",
              "      <th>q9a</th>\n",
              "      <th>q9i</th>\n",
              "      <th>q9e</th>\n",
              "      <th>q10a</th>\n",
              "      <th>q10i</th>\n",
              "      <th>q10e</th>\n",
              "      <th>q11a</th>\n",
              "      <th>q11i</th>\n",
              "      <th>q11e</th>\n",
              "      <th>q12a</th>\n",
              "      <th>q12i</th>\n",
              "      <th>q12e</th>\n",
              "      <th>q13a</th>\n",
              "      <th>q13i</th>\n",
              "      <th>q13e</th>\n",
              "      <th>q14a</th>\n",
              "      <th>q14i</th>\n",
              "      <th>q14e</th>\n",
              "      <th>q15a</th>\n",
              "      <th>q15i</th>\n",
              "      <th>q15e</th>\n",
              "      <th>q16a</th>\n",
              "      <th>q16i</th>\n",
              "      <th>q16e</th>\n",
              "      <th>q17a</th>\n",
              "      <th>q17i</th>\n",
              "      <th>q17e</th>\n",
              "      <th>q18a</th>\n",
              "      <th>q18i</th>\n",
              "      <th>q18e</th>\n",
              "      <th>q19a</th>\n",
              "      <th>q19i</th>\n",
              "      <th>q19e</th>\n",
              "      <th>q20a</th>\n",
              "      <th>q20i</th>\n",
              "      <th>q20e</th>\n",
              "      <th>q21a</th>\n",
              "      <th>q21i</th>\n",
              "      <th>q21e</th>\n",
              "      <th>q22a</th>\n",
              "      <th>q22i</th>\n",
              "      <th>q22e</th>\n",
              "      <th>q23a</th>\n",
              "      <th>q23i</th>\n",
              "      <th>q23e</th>\n",
              "      <th>q24a</th>\n",
              "      <th>q24i</th>\n",
              "      <th>q24e</th>\n",
              "      <th>q25a</th>\n",
              "      <th>q25i</th>\n",
              "      <th>q25e</th>\n",
              "      <th>q26a</th>\n",
              "      <th>q26i</th>\n",
              "      <th>q26e</th>\n",
              "      <th>q27a</th>\n",
              "      <th>q27i</th>\n",
              "      <th>q27e</th>\n",
              "      <th>q28a</th>\n",
              "      <th>q28i</th>\n",
              "      <th>q28e</th>\n",
              "      <th>q29a</th>\n",
              "      <th>q29i</th>\n",
              "      <th>q29e</th>\n",
              "      <th>q30a</th>\n",
              "      <th>q30i</th>\n",
              "      <th>q30e</th>\n",
              "      <th>q31a</th>\n",
              "      <th>q31i</th>\n",
              "      <th>q31e</th>\n",
              "      <th>q32a</th>\n",
              "      <th>q32i</th>\n",
              "      <th>q32e</th>\n",
              "      <th>q33a</th>\n",
              "      <th>q33i</th>\n",
              "      <th>q33e</th>\n",
              "      <th>q34a</th>\n",
              "      <th>q34i</th>\n",
              "      <th>q34e</th>\n",
              "      <th>q35a</th>\n",
              "      <th>q35i</th>\n",
              "      <th>q35e</th>\n",
              "      <th>q36a</th>\n",
              "      <th>q36i</th>\n",
              "      <th>q36e</th>\n",
              "      <th>q37a</th>\n",
              "      <th>q37i</th>\n",
              "      <th>q37e</th>\n",
              "      <th>q38a</th>\n",
              "      <th>q38i</th>\n",
              "      <th>q38e</th>\n",
              "      <th>q39a</th>\n",
              "      <th>q39i</th>\n",
              "      <th>q39e</th>\n",
              "      <th>q40a</th>\n",
              "      <th>q40i</th>\n",
              "      <th>q40e</th>\n",
              "      <th>q41a</th>\n",
              "      <th>q41i</th>\n",
              "      <th>q41e</th>\n",
              "      <th>q42a</th>\n",
              "      <th>q42i</th>\n",
              "      <th>q42e</th>\n",
              "      <th>country</th>\n",
              "      <th>source</th>\n",
              "      <th>introelapse</th>\n",
              "      <th>testelapse</th>\n",
              "      <th>surveyelapse</th>\n",
              "      <th>tipi1</th>\n",
              "      <th>tipi2</th>\n",
              "      <th>tipi3</th>\n",
              "      <th>tipi4</th>\n",
              "      <th>tipi5</th>\n",
              "      <th>tipi6</th>\n",
              "      <th>tipi7</th>\n",
              "      <th>tipi8</th>\n",
              "      <th>tipi9</th>\n",
              "      <th>tipi10</th>\n",
              "      <th>vcl1</th>\n",
              "      <th>vcl2</th>\n",
              "      <th>vcl3</th>\n",
              "      <th>vcl4</th>\n",
              "      <th>vcl5</th>\n",
              "      <th>vcl6</th>\n",
              "      <th>vcl7</th>\n",
              "      <th>vcl8</th>\n",
              "      <th>vcl9</th>\n",
              "      <th>vcl10</th>\n",
              "      <th>vcl11</th>\n",
              "      <th>vcl12</th>\n",
              "      <th>vcl13</th>\n",
              "      <th>vcl14</th>\n",
              "      <th>vcl15</th>\n",
              "      <th>vcl16</th>\n",
              "      <th>education</th>\n",
              "      <th>urban</th>\n",
              "      <th>gender</th>\n",
              "      <th>engnat</th>\n",
              "      <th>age</th>\n",
              "      <th>screensize</th>\n",
              "      <th>uniquenetworklocation</th>\n",
              "      <th>hand</th>\n",
              "      <th>religion</th>\n",
              "      <th>orientation</th>\n",
              "      <th>race</th>\n",
              "      <th>voted</th>\n",
              "      <th>married</th>\n",
              "      <th>familysize</th>\n",
              "      <th>major</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>6116</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>3193</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>12542</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>6150</td>\n",
              "      <td>3</td>\n",
              "      <td>40</td>\n",
              "      <td>6428</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>17001</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>2944</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8626</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>9639</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>6175</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>6008</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>9267</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>5290</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>25694</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>7634</td>\n",
              "      <td>4</td>\n",
              "      <td>37</td>\n",
              "      <td>8513</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>9078</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>4381</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>6647</td>\n",
              "      <td>2</td>\n",
              "      <td>36</td>\n",
              "      <td>6250</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>3842</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>7876</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>3124</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>6836</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>12063</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>9264</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>3957</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>2537</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>10880</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>8462</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>5615</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>11412</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>5112</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>3070</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13377</td>\n",
              "      <td>2</td>\n",
              "      <td>38</td>\n",
              "      <td>4506</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>17227</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>7844</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>20253</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>8528</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4370</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>10310</td>\n",
              "      <td>US</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>349</td>\n",
              "      <td>213</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>70</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>2901</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9036</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>3775</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>2027</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>2714</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3626</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4496</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>3453</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>4619</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>2540</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>2946</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3508</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1727</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>4508</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2490</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3725</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>4826</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>2425</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>3002</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>2371</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>4058</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>2721</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2511</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>2981</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>4554</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1894</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>1541</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>3354</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>3129</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>5256</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5345</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>3058</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>1690</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1686</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>4135</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>1852</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>4181</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1898</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>1389</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>4266</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>1534</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>3449</td>\n",
              "      <td>US</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>143</td>\n",
              "      <td>228</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>Biology and Philosophy dual major</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6729</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4793</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>3328</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>2199</td>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>2513</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>2220</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>2489</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>2570</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5790</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>4348</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5951</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>1973</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>2679</td>\n",
              "      <td>4</td>\n",
              "      <td>33</td>\n",
              "      <td>3425</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>1931</td>\n",
              "      <td>3</td>\n",
              "      <td>28</td>\n",
              "      <td>4472</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>1450</td>\n",
              "      <td>2</td>\n",
              "      <td>40</td>\n",
              "      <td>2006</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>3613</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>1166</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>3214</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>4843</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>1216</td>\n",
              "      <td>3</td>\n",
              "      <td>41</td>\n",
              "      <td>4086</td>\n",
              "      <td>2</td>\n",
              "      <td>37</td>\n",
              "      <td>5170</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>1703</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>2482</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>1741</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>2681</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>2779</td>\n",
              "      <td>3</td>\n",
              "      <td>38</td>\n",
              "      <td>2302</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>3895</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>1313</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>1426</td>\n",
              "      <td>4</td>\n",
              "      <td>31</td>\n",
              "      <td>3803</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2430</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>2035</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>2754</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>2830</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>2357</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>3662</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3372</td>\n",
              "      <td>US</td>\n",
              "      <td>2</td>\n",
              "      <td>73</td>\n",
              "      <td>128</td>\n",
              "      <td>89</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Computer Science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>2236</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1437</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>2570</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>2188</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>3372</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1975</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1579</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>1736</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>11058</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3389</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>2105</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>2218</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>1803</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>3058</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "      <td>4186</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2184</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>3906</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>3128</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>2375</td>\n",
              "      <td>2</td>\n",
              "      <td>42</td>\n",
              "      <td>1957</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1567</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>1334</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2903</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>2473</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>1397</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>2119</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4983</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>3193</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>2454</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>6983</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3281</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>2984</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>1676</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>5516</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>1483</td>\n",
              "      <td>2</td>\n",
              "      <td>33</td>\n",
              "      <td>3556</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>2299</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>2794</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>2537</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>1524</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>2944</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>121</td>\n",
              "      <td>171</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>70</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>3404</td>\n",
              "      <td>2</td>\n",
              "      <td>28</td>\n",
              "      <td>10935</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3593</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>5086</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>2810</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3677</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>4919</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3288</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>8824</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>5750</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>2475</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>2422</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>1638</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>15928</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>2770</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>4719</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>3639</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>1745</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>8400</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>2408</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>3548</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>4149</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>3043</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>3698</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>27429</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>2660</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>2621</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>2219</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2827</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4980</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>2623</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>11105</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>2245</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>5499</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>6972</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1761</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>8120</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6261</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3951</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>2576</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>11750</td>\n",
              "      <td>US</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>221</td>\n",
              "      <td>183</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8202</th>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>3069</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>3561</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>2200</td>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "      <td>3045</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8671</td>\n",
              "      <td>4</td>\n",
              "      <td>30</td>\n",
              "      <td>2186</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>1527</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2236</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>1265</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>2232</td>\n",
              "      <td>4</td>\n",
              "      <td>34</td>\n",
              "      <td>1676</td>\n",
              "      <td>4</td>\n",
              "      <td>40</td>\n",
              "      <td>1716</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>2553</td>\n",
              "      <td>4</td>\n",
              "      <td>39</td>\n",
              "      <td>1797</td>\n",
              "      <td>4</td>\n",
              "      <td>33</td>\n",
              "      <td>1585</td>\n",
              "      <td>4</td>\n",
              "      <td>23</td>\n",
              "      <td>3475</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>2722</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>1785</td>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "      <td>4253</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>2077</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1918</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>1533</td>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>2939</td>\n",
              "      <td>4</td>\n",
              "      <td>37</td>\n",
              "      <td>2699</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8376</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>1452</td>\n",
              "      <td>4</td>\n",
              "      <td>35</td>\n",
              "      <td>1325</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>3080</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>2771</td>\n",
              "      <td>4</td>\n",
              "      <td>31</td>\n",
              "      <td>2336</td>\n",
              "      <td>4</td>\n",
              "      <td>41</td>\n",
              "      <td>2938</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>3676</td>\n",
              "      <td>4</td>\n",
              "      <td>42</td>\n",
              "      <td>1717</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>1301</td>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>4973</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>1492</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>2865</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>1791</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1858</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>6011</td>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>1735</td>\n",
              "      <td>4</td>\n",
              "      <td>36</td>\n",
              "      <td>2849</td>\n",
              "      <td>US</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>115</td>\n",
              "      <td>78</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8203</th>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>3626</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>4161</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>2640</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7369</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>2607</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>2122</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>2473</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>1538</td>\n",
              "      <td>4</td>\n",
              "      <td>37</td>\n",
              "      <td>4779</td>\n",
              "      <td>2</td>\n",
              "      <td>28</td>\n",
              "      <td>2741</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>2389</td>\n",
              "      <td>3</td>\n",
              "      <td>34</td>\n",
              "      <td>2690</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>1320</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>3376</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1621</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "      <td>2038</td>\n",
              "      <td>4</td>\n",
              "      <td>40</td>\n",
              "      <td>2406</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>3810</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>3910</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>2106</td>\n",
              "      <td>3</td>\n",
              "      <td>41</td>\n",
              "      <td>3241</td>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "      <td>2975</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>1722</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2456</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>3008</td>\n",
              "      <td>4</td>\n",
              "      <td>35</td>\n",
              "      <td>2506</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>2991</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2173</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>2574</td>\n",
              "      <td>4</td>\n",
              "      <td>31</td>\n",
              "      <td>6601</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>2957</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>4044</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>2222</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4782</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>6651</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>1604</td>\n",
              "      <td>3</td>\n",
              "      <td>33</td>\n",
              "      <td>3008</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>2206</td>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>2240</td>\n",
              "      <td>4</td>\n",
              "      <td>42</td>\n",
              "      <td>2424</td>\n",
              "      <td>4</td>\n",
              "      <td>36</td>\n",
              "      <td>2106</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>4078</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>128</td>\n",
              "      <td>144</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8204</th>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>2000</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>2055</td>\n",
              "      <td>4</td>\n",
              "      <td>22</td>\n",
              "      <td>2229</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>3527</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1633</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>1032</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>3567</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2608</td>\n",
              "      <td>4</td>\n",
              "      <td>31</td>\n",
              "      <td>2936</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>1848</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>2448</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>4936</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1423</td>\n",
              "      <td>4</td>\n",
              "      <td>40</td>\n",
              "      <td>3063</td>\n",
              "      <td>4</td>\n",
              "      <td>33</td>\n",
              "      <td>1103</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>2240</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>1832</td>\n",
              "      <td>4</td>\n",
              "      <td>23</td>\n",
              "      <td>1383</td>\n",
              "      <td>2</td>\n",
              "      <td>37</td>\n",
              "      <td>3498</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>1760</td>\n",
              "      <td>4</td>\n",
              "      <td>34</td>\n",
              "      <td>1438</td>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>1422</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>2296</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>1289</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>2384</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2207</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>1632</td>\n",
              "      <td>4</td>\n",
              "      <td>36</td>\n",
              "      <td>1544</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>2351</td>\n",
              "      <td>4</td>\n",
              "      <td>35</td>\n",
              "      <td>1824</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5042</td>\n",
              "      <td>4</td>\n",
              "      <td>39</td>\n",
              "      <td>1528</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>1368</td>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>1344</td>\n",
              "      <td>4</td>\n",
              "      <td>41</td>\n",
              "      <td>1889</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4773</td>\n",
              "      <td>4</td>\n",
              "      <td>30</td>\n",
              "      <td>2886</td>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>1592</td>\n",
              "      <td>4</td>\n",
              "      <td>42</td>\n",
              "      <td>1208</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>2679</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>1320</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>1920</td>\n",
              "      <td>US</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>120</td>\n",
              "      <td>221</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>Marketing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8205</th>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>2350</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "      <td>2316</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>2087</td>\n",
              "      <td>4</td>\n",
              "      <td>30</td>\n",
              "      <td>2614</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>1320</td>\n",
              "      <td>4</td>\n",
              "      <td>35</td>\n",
              "      <td>8479</td>\n",
              "      <td>4</td>\n",
              "      <td>36</td>\n",
              "      <td>1443</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>1320</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>2862</td>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>1488</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>12252</td>\n",
              "      <td>4</td>\n",
              "      <td>37</td>\n",
              "      <td>1481</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>1291</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>2200</td>\n",
              "      <td>4</td>\n",
              "      <td>33</td>\n",
              "      <td>3329</td>\n",
              "      <td>4</td>\n",
              "      <td>23</td>\n",
              "      <td>1575</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>1286</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>2491</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>3308</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>1336</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>1555</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>1270</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3946</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>1604</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>6550</td>\n",
              "      <td>4</td>\n",
              "      <td>41</td>\n",
              "      <td>1244</td>\n",
              "      <td>4</td>\n",
              "      <td>39</td>\n",
              "      <td>1256</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>1223</td>\n",
              "      <td>4</td>\n",
              "      <td>40</td>\n",
              "      <td>1841</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3922</td>\n",
              "      <td>4</td>\n",
              "      <td>31</td>\n",
              "      <td>2839</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>2615</td>\n",
              "      <td>4</td>\n",
              "      <td>42</td>\n",
              "      <td>1342</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>1194</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>5597</td>\n",
              "      <td>4</td>\n",
              "      <td>22</td>\n",
              "      <td>1214</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1743</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>1833</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>1371</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3110</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3029</td>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>4222</td>\n",
              "      <td>US</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>116</td>\n",
              "      <td>86</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8206</th>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>28897</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3025</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>3248</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>8048</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3559</td>\n",
              "      <td>4</td>\n",
              "      <td>34</td>\n",
              "      <td>2219</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4553</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>1890</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>4561</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>4071</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>2909</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>5179</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>2190</td>\n",
              "      <td>2</td>\n",
              "      <td>28</td>\n",
              "      <td>52923</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>2126</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>3341</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>3949</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>4455</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>19120</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>4429</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>3372</td>\n",
              "      <td>3</td>\n",
              "      <td>31</td>\n",
              "      <td>3409</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>2538</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>2541</td>\n",
              "      <td>4</td>\n",
              "      <td>35</td>\n",
              "      <td>8110</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>2701</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>2408</td>\n",
              "      <td>3</td>\n",
              "      <td>37</td>\n",
              "      <td>2909</td>\n",
              "      <td>4</td>\n",
              "      <td>42</td>\n",
              "      <td>4100</td>\n",
              "      <td>2</td>\n",
              "      <td>33</td>\n",
              "      <td>13153</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>19343</td>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>5189</td>\n",
              "      <td>3</td>\n",
              "      <td>27</td>\n",
              "      <td>3088</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>2900</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>23056</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>1677</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>15366</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>2718</td>\n",
              "      <td>4</td>\n",
              "      <td>40</td>\n",
              "      <td>4331</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3769</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>4261</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>4709</td>\n",
              "      <td>US</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>300</td>\n",
              "      <td>234</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>70</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8207 rows × 172 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4259e723-4b1b-4320-b7de-1930710bbef6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4259e723-4b1b-4320-b7de-1930710bbef6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4259e723-4b1b-4320-b7de-1930710bbef6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOplAYr41FQ3"
      },
      "source": [
        "##Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforms the Target data into a usable form."
      ],
      "metadata": {
        "id": "P_fLFjz3U-YA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Liw04BKW-o9Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "94e58c21-0918-43fb-d0fd-6e8498772cda"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 39.5 ms (2023-04-23T01:47:29/2023-04-23T01:47:29)</pre>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Finds the Depression, Anxiety, and Stress score on each row and assigns a score.\n",
        "Modeldf = pd.DataFrame()\n",
        "\n",
        "DepressionTarg = ['q3a', 'q5a', 'q10a', 'q13a', 'q16a', 'q17a', 'q21a', 'q24a', 'q26a', 'q31a', 'q34a', 'q37a', 'q38a', 'q42a']\n",
        "AnxietyTarg = ['q2a', 'q4a', 'q7a', 'q9a', 'q15a', 'q19a', 'q20a', 'q23a', 'q25a', 'q28a', 'q30a', 'q36a', 'q40a', 'q41a']\n",
        "StressTarg = ['q1a', 'q6a', 'q8a', 'q11a', 'q12a', 'q14a', 'q18a', 'q22a', 'q27a', 'q29a', 'q32a', 'q33a', 'q35a', 'q39a']\n",
        "\n",
        "features = []\n",
        "targets = []\n",
        "\n",
        "Depression = 0\n",
        "Anxiety = 0\n",
        "Stress = 0\n",
        "\n",
        "#Decrements the saved answers by one due to incorrrect storing in the Dataframe.\n",
        "for i in DepressionTarg:\n",
        "  Depression = sum([Depression, (df[i]-1)])\n",
        "\n",
        "for i in AnxietyTarg:\n",
        "  Anxiety = sum([Anxiety, (df[i]-1)])\n",
        "\n",
        "for i in StressTarg:\n",
        "  Stress = sum([Stress, (df[i]-1)])\n",
        "\n",
        "Modeldf['Depression_Score'] = Depression\n",
        "Modeldf['Anxiety_Score'] = Anxiety\n",
        "Modeldf['Stress_Score'] = Stress\n",
        "\n",
        "targets = targets + ['Depression_Score', 'Anxiety_Score', 'Stress_Score']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Takes the catigorical features and breaks it up into multiple binary features."
      ],
      "metadata": {
        "id": "2HBzsKutVEZ4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "eoT9U6O7ah9v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0e582a33-2106-4b0c-d6a3-aa6fbaeea7d2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 2.5 s (2023-04-23T01:47:29/2023-04-23T01:47:32)</pre>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Breaks the eduction column into more binary columns.\n",
        "Modeldf['No_Degree'] = 0\n",
        "Modeldf['HighSchool'] = 0\n",
        "Modeldf['University'] = 0\n",
        "Modeldf['Graduate'] = 0\n",
        "\n",
        "ELoc = df.columns.get_loc('education')\n",
        "\n",
        "NDLoc = Modeldf.columns.get_loc('No_Degree')\n",
        "HSLoc = Modeldf.columns.get_loc('HighSchool')\n",
        "ULoc = Modeldf.columns.get_loc('University')\n",
        "GLoc = Modeldf.columns.get_loc('Graduate')\n",
        "\n",
        "for i in range(len(df)):\n",
        "  if df.iat[i,ELoc] == 1:\n",
        "    Modeldf.iat[i,NDLoc] = 1\n",
        "\n",
        "  elif df.iat[i,ELoc] == 2:\n",
        "    Modeldf.iat[i,HSLoc] = 1\n",
        "\n",
        "  elif df.iat[i,ELoc] == 3:\n",
        "    Modeldf.iat[i,ULoc] = 1\n",
        "\n",
        "  elif df.iat[i,ELoc] == 4:\n",
        "    Modeldf.iat[i,GLoc] = 1\n",
        "\n",
        "features = features + ['No_Degree', 'HighSchool', 'University', 'Graduate']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "s-00CbDVgxyb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "038168b7-cf76-48f9-c6ca-1d975184b6ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 936 ms (2023-04-23T01:47:32/2023-04-23T01:47:33)</pre>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Breaks the urban column into more binary columns.\n",
        "Modeldf['Rual'] = 0\n",
        "Modeldf['Suburban'] = 0\n",
        "Modeldf['Urban'] = 0\n",
        "\n",
        "Urloc = df.columns.get_loc('urban')\n",
        "\n",
        "RLoc = Modeldf.columns.get_loc('Rual')\n",
        "SULoc = Modeldf.columns.get_loc('Suburban')\n",
        "ULoc = Modeldf.columns.get_loc('Urban')\n",
        "\n",
        "\n",
        "for i in range(len(df)):\n",
        "  if df.iat[i,Urloc] == 1:\n",
        "    Modeldf.iat[i,RLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Urloc] == 2:\n",
        "    Modeldf.iat[i,SULoc] = 1\n",
        "\n",
        "  elif df.iat[i,Urloc] == 3:\n",
        "    Modeldf.iat[i,ULoc] = 1\n",
        "\n",
        "features = features + ['Rual', 'Suburban', 'Urban']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "lhea8Nl6I7MI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ae7425ad-f97f-4511-d207-aee86ff2ee1e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 785 ms (2023-04-23T01:47:33/2023-04-23T01:47:34)</pre>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Breaks the gender column into more binary columns.\n",
        "Modeldf['Male'] = 0\n",
        "Modeldf['Female'] = 0\n",
        "Modeldf['Other_Gender'] = 0\n",
        "\n",
        "gloc = df.columns.get_loc('gender')\n",
        "\n",
        "mLoc = Modeldf.columns.get_loc('Male')\n",
        "fLoc = Modeldf.columns.get_loc('Female')\n",
        "oLoc = Modeldf.columns.get_loc('Other_Gender')\n",
        "\n",
        "\n",
        "for i in range(len(df)):\n",
        "  if df.iat[i,gloc] == 1:\n",
        "    Modeldf.iat[i,mLoc] = 1\n",
        "\n",
        "  elif df.iat[i,gloc] == 2:\n",
        "    Modeldf.iat[i,fLoc] = 1\n",
        "\n",
        "  elif df.iat[i,gloc] == 3:\n",
        "    Modeldf.iat[i,oLoc] = 1\n",
        "\n",
        "features = features + ['Male', 'Female', 'Other_Gender']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "9DN6yasKKI1G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b0fee111-dafe-42c1-b3e7-9c3c3c31b068"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 553 ms (2023-04-23T01:47:34/2023-04-23T01:47:34)</pre>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Normalizes the engnat column into more binary columns.\n",
        "Modeldf['Engnat'] = 0\n",
        "\n",
        "eloc = df.columns.get_loc('engnat')\n",
        "\n",
        "newELoc = Modeldf.columns.get_loc('Engnat')\n",
        "\n",
        "\n",
        "for i in range(len(df)):\n",
        "  if df.iat[i,eloc] == 1:\n",
        "    Modeldf.iat[i,newELoc] = 1\n",
        "\n",
        "features = features + ['Engnat']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "jerGqHteKw22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "55f41946-9844-4260-f01c-425311689ee1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 654 ms (2023-04-23T01:47:34/2023-04-23T01:47:35)</pre>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Breaks the hand column into more binary columns.\n",
        "Modeldf['Right_h'] = 0\n",
        "Modeldf['Left_h'] = 0\n",
        "Modeldf['Ambidextrous'] = 0\n",
        "\n",
        "hloc = df.columns.get_loc('hand')\n",
        "\n",
        "rLoc = Modeldf.columns.get_loc('Right_h')\n",
        "lLoc = Modeldf.columns.get_loc('Left_h')\n",
        "aLoc = Modeldf.columns.get_loc('Ambidextrous')\n",
        "\n",
        "\n",
        "for i in range(len(df)):\n",
        "  if df.iat[i,hloc] == 1:\n",
        "    Modeldf.iat[i,rLoc] = 1\n",
        "\n",
        "  elif df.iat[i,hloc] == 2:\n",
        "    Modeldf.iat[i,lLoc] = 1\n",
        "\n",
        "  elif df.iat[i,hloc] == 3:\n",
        "    Modeldf.iat[i,aLoc] = 1\n",
        "\n",
        "features = features + ['Right_h', 'Left_h', 'Ambidextrous']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "KyScZFDvLp_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4806eb55-a100-4a8b-b772-30f401fcab11"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 1.58 s (2023-04-23T01:47:35/2023-04-23T01:47:37)</pre>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Breaks the religion column into more binary columns.\n",
        "Modeldf['Agnostic'] = 0\n",
        "Modeldf['Atheist'] = 0\n",
        "Modeldf['Buddhist'] = 0\n",
        "Modeldf['Catholic'] = 0\n",
        "Modeldf['Mormon'] = 0\n",
        "Modeldf['Protestant'] = 0\n",
        "Modeldf['Other_Christian'] = 0\n",
        "Modeldf['Hindu'] = 0\n",
        "Modeldf['Jewish'] = 0\n",
        "Modeldf['Muslim'] = 0\n",
        "Modeldf['Sikh'] = 0\n",
        "Modeldf['Other_Religion'] = 0\n",
        "\n",
        "Reloc = df.columns.get_loc('religion')\n",
        "\n",
        "agLoc = Modeldf.columns.get_loc('Agnostic')\n",
        "athLoc = Modeldf.columns.get_loc('Atheist')\n",
        "bLoc = Modeldf.columns.get_loc('Buddhist')\n",
        "caLoc = Modeldf.columns.get_loc('Catholic')\n",
        "moLoc = Modeldf.columns.get_loc('Mormon')\n",
        "pLoc = Modeldf.columns.get_loc('Protestant')\n",
        "ocLoc = Modeldf.columns.get_loc('Other_Christian')\n",
        "hLoc = Modeldf.columns.get_loc('Hindu')\n",
        "jLoc = Modeldf.columns.get_loc('Jewish')\n",
        "muLoc = Modeldf.columns.get_loc('Muslim')\n",
        "siLoc = Modeldf.columns.get_loc('Sikh')\n",
        "orLoc = Modeldf.columns.get_loc('Other_Religion')\n",
        "\n",
        "\n",
        "for i in range(len(df)):\n",
        "  if df.iat[i,Reloc] == 1:\n",
        "    Modeldf.iat[i,agLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Reloc] == 2:\n",
        "    Modeldf.iat[i,athLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Reloc] == 3:\n",
        "    Modeldf.iat[i,bLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Reloc] == 4:\n",
        "    Modeldf.iat[i,caLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Reloc] == 5:\n",
        "    Modeldf.iat[i,moLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Reloc] == 6:\n",
        "    Modeldf.iat[i,pLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Reloc] == 7:\n",
        "    Modeldf.iat[i,ocLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Reloc] == 8:\n",
        "    Modeldf.iat[i,hLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Reloc] == 9:\n",
        "    Modeldf.iat[i,jLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Reloc] == 10:\n",
        "    Modeldf.iat[i,muLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Reloc] == 11:\n",
        "    Modeldf.iat[i,siLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Reloc] == 12:\n",
        "    Modeldf.iat[i,orLoc] = 1\n",
        "\n",
        "features = features + ['Agnostic', 'Atheist', 'Buddhist', 'Catholic', 'Mormon', 'Protestant', 'Other_Christian', 'Hindu', 'Jewish', 'Muslim', 'Sikh', 'Other_Religion']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "UPS6mn02Nmgb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "525e592d-dd03-4614-daab-65fd0656781b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 514 ms (2023-04-23T01:47:37/2023-04-23T01:47:37)</pre>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Breaks the orientation column into more binary columns.\n",
        "Modeldf['Heterosexual'] = 0\n",
        "Modeldf['Bisexual'] = 0\n",
        "Modeldf['Homosexual'] = 0\n",
        "Modeldf['Asexual'] = 0\n",
        "Modeldf['Other_Orientation'] = 0\n",
        "\n",
        "Orloc = df.columns.get_loc('orientation')\n",
        "\n",
        "HeLoc = Modeldf.columns.get_loc('Heterosexual')\n",
        "BLoc = Modeldf.columns.get_loc('Bisexual')\n",
        "HoLoc = Modeldf.columns.get_loc('Homosexual')\n",
        "AsLoc = Modeldf.columns.get_loc('Asexual')\n",
        "OtLoc = Modeldf.columns.get_loc('Other_Orientation')\n",
        "\n",
        "\n",
        "for i in range(len(df)):\n",
        "  if df.iat[i,Orloc] == 1:\n",
        "    Modeldf.iat[i,HeLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Orloc] == 2:\n",
        "    Modeldf.iat[i,BLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Orloc] == 3:\n",
        "    Modeldf.iat[i,HoLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Orloc] == 4:\n",
        "    Modeldf.iat[i,AsLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Orloc] == 5:\n",
        "    Modeldf.iat[i,OtLoc] = 1\n",
        "\n",
        "features = features + ['Heterosexual', 'Bisexual', 'Homosexual', 'Asexual', 'Other_Orientation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "S7q_UpEwOXMj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5287eee3-9714-402d-cb64-d0ab98983973"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 1.18 s (2023-04-23T01:47:37/2023-04-23T01:47:38)</pre>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Breaks the race column into more binary columns.\n",
        "Modeldf['Asian'] = 0\n",
        "Modeldf['Arab'] = 0\n",
        "Modeldf['Black'] = 0\n",
        "Modeldf['Indigenous_Australian'] = 0\n",
        "Modeldf['Native_American'] = 0\n",
        "Modeldf['White'] = 0\n",
        "Modeldf['Other_Race'] = 0\n",
        "\n",
        "Raloc = df.columns.get_loc('race')\n",
        "\n",
        "AsLoc = Modeldf.columns.get_loc('Asian')\n",
        "ArhLoc = Modeldf.columns.get_loc('Arab')\n",
        "BlLoc = Modeldf.columns.get_loc('Black')\n",
        "IaLoc = Modeldf.columns.get_loc('Indigenous_Australian')\n",
        "NaLoc = Modeldf.columns.get_loc('Native_American')\n",
        "WLoc = Modeldf.columns.get_loc('White')\n",
        "OrLoc = Modeldf.columns.get_loc('Other_Race')\n",
        "\n",
        "\n",
        "for i in range(len(df)):\n",
        "  if df.iat[i,Raloc] == 10:\n",
        "    Modeldf.iat[i,AsLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Raloc] == 20:\n",
        "    Modeldf.iat[i,ArhLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Raloc] == 30:\n",
        "    Modeldf.iat[i,BlLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Raloc] == 40:\n",
        "    Modeldf.iat[i,IaLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Raloc] == 50:\n",
        "    Modeldf.iat[i,NaLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Raloc] == 60:\n",
        "    Modeldf.iat[i,WLoc] = 1\n",
        "\n",
        "  elif df.iat[i,Raloc] == 70:\n",
        "    Modeldf.iat[i,OrLoc] = 1\n",
        "\n",
        "features = features + ['Asian', 'Arab', 'Black', 'Indigenous_Australian', 'Native_American', 'White', 'Other_Race']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "DuU_NNexPsn-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "71b65a80-1a2e-4ea3-b3f6-fd1f408d759d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 257 ms (2023-04-23T01:47:39/2023-04-23T01:47:39)</pre>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Normalizes the voted column into more binary columns.\n",
        "Modeldf['Voted'] = 0\n",
        "\n",
        "vloc = df.columns.get_loc('voted')\n",
        "\n",
        "newVLoc = Modeldf.columns.get_loc('Voted')\n",
        "\n",
        "\n",
        "for i in range(len(df)):\n",
        "  if df.iat[i,vloc] == 1:\n",
        "    Modeldf.iat[i,newVLoc] = 1\n",
        "\n",
        "features = features + ['Voted']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "45qg7RY3QGCA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8106679d-9d38-4a9f-9be8-d97c6003baf4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 443 ms (2023-04-23T01:47:39/2023-04-23T01:47:39)</pre>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Breaks the married column into more binary columns.\n",
        "Modeldf['Never_married'] = 0\n",
        "Modeldf['Married'] = 0\n",
        "Modeldf['Previously_married'] = 0\n",
        "\n",
        "mloc = df.columns.get_loc('married')\n",
        "\n",
        "NmLoc = Modeldf.columns.get_loc('Never_married')\n",
        "MaLoc = Modeldf.columns.get_loc('Married')\n",
        "PmLoc = Modeldf.columns.get_loc('Previously_married')\n",
        "\n",
        "\n",
        "for i in range(len(df)):\n",
        "  if df.iat[i,mloc] == 1:\n",
        "    Modeldf.iat[i,NmLoc] = 1\n",
        "\n",
        "  elif df.iat[i,mloc] == 2:\n",
        "    Modeldf.iat[i,MaLoc] = 1\n",
        "\n",
        "  elif df.iat[i,mloc] == 3:\n",
        "    Modeldf.iat[i,PmLoc] = 1\n",
        "\n",
        "features = features + ['Never_married', 'Married', 'Previously_married']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Takes the data from the TIPI questions and changes it to a usable form."
      ],
      "metadata": {
        "id": "yxFUdCRTVXJe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "BEl8ZDPR1C3m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f39c51ef-ddbe-4ef5-f588-07200dcb83a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 5.03 s (2023-04-23T01:47:39/2023-04-23T01:47:44)</pre>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Changing the TIPI answers to a usable form.\n",
        "#Only Run this cell ONCE!\n",
        "NomScore = ['tipi1', 'tipi7', 'tipi3', 'tipi9', 'tipi5']\n",
        "RevScore = ['tipi6', 'tipi2', 'tipi8', 'tipi4', 'tipi10']\n",
        "\n",
        "Rev1 = df.columns.get_loc('tipi6')\n",
        "Rev2 = df.columns.get_loc('tipi2')\n",
        "Rev3 = df.columns.get_loc('tipi8')\n",
        "Rev4 = df.columns.get_loc('tipi4')\n",
        "Rev5 = df.columns.get_loc('tipi10')\n",
        "\n",
        "RevLocs = [Rev1, Rev2, Rev3, Rev4, Rev5]\n",
        "\n",
        "for j in RevLocs:\n",
        "  for i in range(len(df)):\n",
        "    if df.iat[i,j] == 1:\n",
        "      df.iat[i,j] = 7\n",
        "\n",
        "    elif df.iat[i,j] == 2:\n",
        "      df.iat[i,j] = 6\n",
        "\n",
        "    elif df.iat[i,j] == 3:\n",
        "      df.iat[i,j] = 5\n",
        "\n",
        "    elif df.iat[i,j] == 4:\n",
        "      df.iat[i,j] = 4\n",
        "\n",
        "    elif df.iat[i,j] == 5:\n",
        "      df.iat[i,j] = 3\n",
        "\n",
        "    elif df.iat[i,j] == 6:\n",
        "      df.iat[i,j] = 2\n",
        "\n",
        "    elif df.iat[i,j] == 7:\n",
        "      df.iat[i,j] = 1\n",
        "\n",
        "df['Extraversion'] = (df[NomScore[0]] + df[RevScore[0]])/2\n",
        "df['Agreeableness'] = (df[NomScore[1]] + df[RevScore[1]])/2\n",
        "df['Conscientiousness'] = (df[NomScore[2]] + df[RevScore[2]])/2\n",
        "df['Emotional_Stability'] = (df[NomScore[3]] + df[RevScore[3]])/2\n",
        "df['Openness'] = (df[NomScore[4]] + df[RevScore[4]])/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1bmmJH41o8v"
      },
      "source": [
        "###Normalize the data so all continuous values is on a 0 to 1 scale to match the other features which are categorical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "drDSk9utUxNp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fdfc43f4-1fdf-4bbe-a98b-f556a513707d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 50.5 ms (2023-04-23T01:47:44/2023-04-23T01:47:44)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-71-cf899db73ca0>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sidedf['Extraversion'] = df['Extraversion']\n",
            "<ipython-input-71-cf899db73ca0>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sidedf['Agreeableness'] = df['Agreeableness']\n",
            "<ipython-input-71-cf899db73ca0>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sidedf['Conscientiousness'] = df['Conscientiousness']\n",
            "<ipython-input-71-cf899db73ca0>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sidedf['Emotional_Stability'] = df['Emotional_Stability']\n",
            "<ipython-input-71-cf899db73ca0>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sidedf['Openness'] = df['Openness']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           age  familysize  Extraversion  Agreeableness  Conscientiousness   \n",
              "0     0.081395    0.030075      0.214286       1.000000           0.857143  \\\n",
              "1     0.244186    0.015038      0.428571       0.428571           0.857143   \n",
              "2     0.069767    0.007519      0.357143       0.357143           0.571429   \n",
              "3     0.034884    0.022556      0.428571       0.714286           0.571429   \n",
              "4     0.058140    0.015038      0.857143       0.571429           0.857143   \n",
              "...        ...         ...           ...            ...                ...   \n",
              "8202  0.104651    0.022556      0.142857       0.642857           0.142857   \n",
              "8203  0.058140    0.015038      0.357143       0.571429           0.714286   \n",
              "8204  0.383721    0.045113      0.357143       0.428571           0.857143   \n",
              "8205  0.011628    0.022556      0.428571       0.428571           0.214286   \n",
              "8206  0.034884    0.022556      0.785714       0.571429           0.714286   \n",
              "\n",
              "      Emotional_Stability  Openness  \n",
              "0                0.928571  0.571429  \n",
              "1                1.000000  0.857143  \n",
              "2                0.928571  0.857143  \n",
              "3                0.928571  0.571429  \n",
              "4                0.928571  0.928571  \n",
              "...                   ...       ...  \n",
              "8202             0.357143  0.785714  \n",
              "8203             0.142857  0.642857  \n",
              "8204             0.214286  0.642857  \n",
              "8205             0.142857  0.357143  \n",
              "8206             0.571429  0.500000  \n",
              "\n",
              "[8207 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ddfcf88-4ef3-48f3-b38d-371ac78476d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>familysize</th>\n",
              "      <th>Extraversion</th>\n",
              "      <th>Agreeableness</th>\n",
              "      <th>Conscientiousness</th>\n",
              "      <th>Emotional_Stability</th>\n",
              "      <th>Openness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.081395</td>\n",
              "      <td>0.030075</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.244186</td>\n",
              "      <td>0.015038</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.069767</td>\n",
              "      <td>0.007519</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.034884</td>\n",
              "      <td>0.022556</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.058140</td>\n",
              "      <td>0.015038</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.928571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8202</th>\n",
              "      <td>0.104651</td>\n",
              "      <td>0.022556</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.785714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8203</th>\n",
              "      <td>0.058140</td>\n",
              "      <td>0.015038</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.642857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8204</th>\n",
              "      <td>0.383721</td>\n",
              "      <td>0.045113</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.642857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8205</th>\n",
              "      <td>0.011628</td>\n",
              "      <td>0.022556</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.357143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8206</th>\n",
              "      <td>0.034884</td>\n",
              "      <td>0.022556</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8207 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ddfcf88-4ef3-48f3-b38d-371ac78476d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ddfcf88-4ef3-48f3-b38d-371ac78476d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ddfcf88-4ef3-48f3-b38d-371ac78476d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Normailizes the non-categorical data.\n",
        "normal = MinMaxScaler()\n",
        "\n",
        "sidedf = pd.DataFrame()\n",
        "sidedf = df[['age', 'familysize']]   \n",
        "sidedf['Extraversion'] = df['Extraversion']\n",
        "sidedf['Agreeableness'] = df['Agreeableness']\n",
        "sidedf['Conscientiousness'] = df['Conscientiousness']\n",
        "sidedf['Emotional_Stability'] = df['Emotional_Stability']\n",
        "sidedf['Openness'] = df['Openness']\n",
        "                      \n",
        "Modeldf['Age'] = 0\n",
        "Modeldf['FamilySize'] = 0\n",
        "\n",
        "sidedf = pd.DataFrame(normal.fit_transform(sidedf), columns=['age','familysize', 'Extraversion', 'Agreeableness', 'Conscientiousness', 'Emotional_Stability', 'Openness'])\n",
        "\n",
        "Modeldf['Age'] = sidedf['age']\n",
        "Modeldf['FamilySize'] = sidedf['familysize']\n",
        "Modeldf['Extraversion'] = sidedf['Extraversion']\n",
        "Modeldf['Agreeableness'] = sidedf['Agreeableness']\n",
        "Modeldf['Conscientiousness'] = sidedf['Conscientiousness']\n",
        "Modeldf['Emotional_Stability'] = sidedf['Emotional_Stability']\n",
        "Modeldf['Openness'] = sidedf['Openness']\n",
        "ut.pprint(sidedf)\n",
        "features = features + ['Age', 'FamilySize', 'Extraversion', 'Agreeableness', 'Conscientiousness', 'Emotional_Stability', 'Openness']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Splitting the data for classification and Regression Approach"
      ],
      "metadata": {
        "id": "K8kLqWylSwKN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the target data can be a catigorical value or a continus value, I decided try some regrssive models and then classifers to see what gives better results."
      ],
      "metadata": {
        "id": "ttDD5kY-UGE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Classdf = Modeldf\n",
        "Regressiondf = Modeldf"
      ],
      "metadata": {
        "id": "5IkZS27CJD-H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e7a1df1-5b47-46fc-bcb5-51355e1e9a34"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 781 µs (2023-04-23T01:47:45/2023-04-23T01:47:45)</pre>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Regression Approch"
      ],
      "metadata": {
        "id": "sUxogZ5dbXoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Examining the Data before Regression"
      ],
      "metadata": {
        "id": "fS-Q_DA0cnH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression Data is checked and verified that all preprocessing steps executed correctly."
      ],
      "metadata": {
        "id": "HsYkYykd2aKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Regressiondf = Modeldf\n",
        "display(Regressiondf.describe(include='all'))\n",
        "ut.pprint(Regressiondf)\n",
        "\n",
        "print(np.sum(Modeldf[['Depression_Score']] >= 28))"
      ],
      "metadata": {
        "id": "P6pZ7-C4cnH6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "outputId": "a3cbc1ce-75d5-4319-a65c-45671181c19f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 345 ms (2023-04-22T22:53:41/2023-04-22T22:53:41)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Depression_Score  Anxiety_Score  Stress_Score    No_Degree   \n",
              "count            8207.0         8207.0        8207.0  8207.000000  \\\n",
              "mean          22.060436      15.794687      22.07189     0.270135   \n",
              "std           12.678143      10.721868     10.743251     0.444057   \n",
              "min                 0.0            0.0           0.0     0.000000   \n",
              "25%                11.0            7.0          14.0     0.000000   \n",
              "50%                22.0           14.0          22.0     0.000000   \n",
              "75%                33.0           23.0          30.0     1.000000   \n",
              "max                42.0           42.0          42.0     1.000000   \n",
              "\n",
              "        HighSchool   University     Graduate         Rual     Suburban   \n",
              "count  8207.000000  8207.000000  8207.000000  8207.000000  8207.000000  \\\n",
              "mean      0.430974     0.202876     0.083343     0.193493     0.458145   \n",
              "std       0.495243     0.402165     0.276418     0.395060     0.498275   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       1.000000     0.000000     0.000000     0.000000     1.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "             Urban         Male       Female  Other_Gender       Engnat   \n",
              "count  8207.000000  8207.000000  8207.000000   8207.000000  8207.000000  \\\n",
              "mean      0.339344     0.291946     0.666870      0.038869     0.909955   \n",
              "std       0.473516     0.454685     0.471361      0.193295     0.286264   \n",
              "min       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000      0.000000     1.000000   \n",
              "50%       0.000000     0.000000     1.000000      0.000000     1.000000   \n",
              "75%       1.000000     1.000000     1.000000      0.000000     1.000000   \n",
              "max       1.000000     1.000000     1.000000      1.000000     1.000000   \n",
              "\n",
              "           Right_h       Left_h  Ambidextrous     Agnostic      Atheist   \n",
              "count  8207.000000  8207.000000   8207.000000  8207.000000  8207.000000  \\\n",
              "mean      0.859023     0.101133      0.036067     0.197027     0.191178   \n",
              "std       0.348019     0.301523      0.186468     0.397777     0.393253   \n",
              "min       0.000000     0.000000      0.000000     0.000000     0.000000   \n",
              "25%       1.000000     0.000000      0.000000     0.000000     0.000000   \n",
              "50%       1.000000     0.000000      0.000000     0.000000     0.000000   \n",
              "75%       1.000000     0.000000      0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000      1.000000     1.000000     1.000000   \n",
              "\n",
              "          Buddhist     Catholic       Mormon  Protestant  Other_Christian   \n",
              "count  8207.000000  8207.000000  8207.000000  8207.00000      8207.000000  \\\n",
              "mean      0.013038     0.144511     0.010966     0.08968         0.171073   \n",
              "std       0.113443     0.351628     0.104150     0.28574         0.376596   \n",
              "min       0.000000     0.000000     0.000000     0.00000         0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.00000         0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.00000         0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.00000         0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.00000         1.000000   \n",
              "\n",
              "             Hindu       Jewish       Muslim         Sikh  Other_Religion   \n",
              "count  8207.000000  8207.000000  8207.000000  8207.000000     8207.000000  \\\n",
              "mean      0.005239     0.013525     0.024248     0.001218        0.120141   \n",
              "std       0.072198     0.115515     0.153826     0.034887        0.325147   \n",
              "min       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000        1.000000   \n",
              "\n",
              "       Heterosexual     Bisexual   Homosexual     Asexual  Other_Orientation   \n",
              "count   8207.000000  8207.000000  8207.000000  8207.00000        8207.000000  \\\n",
              "mean       0.610454     0.204947     0.061411     0.04155           0.061533   \n",
              "std        0.487677     0.403687     0.240097     0.19957           0.240320   \n",
              "min        0.000000     0.000000     0.000000     0.00000           0.000000   \n",
              "25%        0.000000     0.000000     0.000000     0.00000           0.000000   \n",
              "50%        1.000000     0.000000     0.000000     0.00000           0.000000   \n",
              "75%        1.000000     0.000000     0.000000     0.00000           0.000000   \n",
              "max        1.000000     1.000000     1.000000     1.00000           1.000000   \n",
              "\n",
              "             Asian         Arab        Black  Indigenous_Australian   \n",
              "count  8207.000000  8207.000000  8207.000000            8207.000000  \\\n",
              "mean      0.086755     0.004386     0.046424               0.000122   \n",
              "std       0.281493     0.066089     0.210414               0.011038   \n",
              "min       0.000000     0.000000     0.000000               0.000000   \n",
              "25%       0.000000     0.000000     0.000000               0.000000   \n",
              "50%       0.000000     0.000000     0.000000               0.000000   \n",
              "75%       0.000000     0.000000     0.000000               0.000000   \n",
              "max       1.000000     1.000000     1.000000               1.000000   \n",
              "\n",
              "       Native_American        White   Other_Race        Voted  Never_married   \n",
              "count      8207.000000  8207.000000  8207.000000  8207.000000    8207.000000  \\\n",
              "mean          0.017546     0.717193     0.127574     0.295601       0.783234   \n",
              "std           0.131302     0.450391     0.333635     0.456340       0.412067   \n",
              "min           0.000000     0.000000     0.000000     0.000000       0.000000   \n",
              "25%           0.000000     0.000000     0.000000     0.000000       1.000000   \n",
              "50%           0.000000     1.000000     0.000000     0.000000       1.000000   \n",
              "75%           0.000000     1.000000     0.000000     1.000000       1.000000   \n",
              "max           1.000000     1.000000     1.000000     1.000000       1.000000   \n",
              "\n",
              "           Married  Previously_married          Age   FamilySize   \n",
              "count  8207.000000         8207.000000  8207.000000  8207.000000  \\\n",
              "mean      0.149872            0.062020     0.135942     0.020582   \n",
              "std       0.356968            0.241207     0.144729     0.016407   \n",
              "min       0.000000            0.000000     0.000000     0.000000   \n",
              "25%       0.000000            0.000000     0.034884     0.015038   \n",
              "50%       0.000000            0.000000     0.081395     0.015038   \n",
              "75%       0.000000            0.000000     0.174419     0.022556   \n",
              "max       1.000000            1.000000     1.000000     1.000000   \n",
              "\n",
              "       Extraversion  Agreeableness  Conscientiousness  Emotional_Stability   \n",
              "count   8207.000000    8207.000000        8207.000000          8207.000000  \\\n",
              "mean       0.449416       0.650412           0.617261             0.431165   \n",
              "std        0.242194       0.201655           0.233309             0.227893   \n",
              "min        0.000000       0.000000           0.000000             0.000000   \n",
              "25%        0.214286       0.500000           0.428571             0.285714   \n",
              "50%        0.428571       0.642857           0.642857             0.357143   \n",
              "75%        0.642857       0.785714           0.785714             0.571429   \n",
              "max        1.000000       1.000000           1.000000             1.000000   \n",
              "\n",
              "          Openness  \n",
              "count  8207.000000  \n",
              "mean      0.687096  \n",
              "std       0.207827  \n",
              "min       0.000000  \n",
              "25%       0.571429  \n",
              "50%       0.714286  \n",
              "75%       0.857143  \n",
              "max       1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06dd08b3-8b09-4147-9293-1380a908a14e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Depression_Score</th>\n",
              "      <th>Anxiety_Score</th>\n",
              "      <th>Stress_Score</th>\n",
              "      <th>No_Degree</th>\n",
              "      <th>HighSchool</th>\n",
              "      <th>University</th>\n",
              "      <th>Graduate</th>\n",
              "      <th>Rual</th>\n",
              "      <th>Suburban</th>\n",
              "      <th>Urban</th>\n",
              "      <th>Male</th>\n",
              "      <th>Female</th>\n",
              "      <th>Other_Gender</th>\n",
              "      <th>Engnat</th>\n",
              "      <th>Right_h</th>\n",
              "      <th>Left_h</th>\n",
              "      <th>Ambidextrous</th>\n",
              "      <th>Agnostic</th>\n",
              "      <th>Atheist</th>\n",
              "      <th>Buddhist</th>\n",
              "      <th>Catholic</th>\n",
              "      <th>Mormon</th>\n",
              "      <th>Protestant</th>\n",
              "      <th>Other_Christian</th>\n",
              "      <th>Hindu</th>\n",
              "      <th>Jewish</th>\n",
              "      <th>Muslim</th>\n",
              "      <th>Sikh</th>\n",
              "      <th>Other_Religion</th>\n",
              "      <th>Heterosexual</th>\n",
              "      <th>Bisexual</th>\n",
              "      <th>Homosexual</th>\n",
              "      <th>Asexual</th>\n",
              "      <th>Other_Orientation</th>\n",
              "      <th>Asian</th>\n",
              "      <th>Arab</th>\n",
              "      <th>Black</th>\n",
              "      <th>Indigenous_Australian</th>\n",
              "      <th>Native_American</th>\n",
              "      <th>White</th>\n",
              "      <th>Other_Race</th>\n",
              "      <th>Voted</th>\n",
              "      <th>Never_married</th>\n",
              "      <th>Married</th>\n",
              "      <th>Previously_married</th>\n",
              "      <th>Age</th>\n",
              "      <th>FamilySize</th>\n",
              "      <th>Extraversion</th>\n",
              "      <th>Agreeableness</th>\n",
              "      <th>Conscientiousness</th>\n",
              "      <th>Emotional_Stability</th>\n",
              "      <th>Openness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8207.0</td>\n",
              "      <td>8207.0</td>\n",
              "      <td>8207.0</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.00000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.00000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>22.060436</td>\n",
              "      <td>15.794687</td>\n",
              "      <td>22.07189</td>\n",
              "      <td>0.270135</td>\n",
              "      <td>0.430974</td>\n",
              "      <td>0.202876</td>\n",
              "      <td>0.083343</td>\n",
              "      <td>0.193493</td>\n",
              "      <td>0.458145</td>\n",
              "      <td>0.339344</td>\n",
              "      <td>0.291946</td>\n",
              "      <td>0.666870</td>\n",
              "      <td>0.038869</td>\n",
              "      <td>0.909955</td>\n",
              "      <td>0.859023</td>\n",
              "      <td>0.101133</td>\n",
              "      <td>0.036067</td>\n",
              "      <td>0.197027</td>\n",
              "      <td>0.191178</td>\n",
              "      <td>0.013038</td>\n",
              "      <td>0.144511</td>\n",
              "      <td>0.010966</td>\n",
              "      <td>0.08968</td>\n",
              "      <td>0.171073</td>\n",
              "      <td>0.005239</td>\n",
              "      <td>0.013525</td>\n",
              "      <td>0.024248</td>\n",
              "      <td>0.001218</td>\n",
              "      <td>0.120141</td>\n",
              "      <td>0.610454</td>\n",
              "      <td>0.204947</td>\n",
              "      <td>0.061411</td>\n",
              "      <td>0.04155</td>\n",
              "      <td>0.061533</td>\n",
              "      <td>0.086755</td>\n",
              "      <td>0.004386</td>\n",
              "      <td>0.046424</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>0.017546</td>\n",
              "      <td>0.717193</td>\n",
              "      <td>0.127574</td>\n",
              "      <td>0.295601</td>\n",
              "      <td>0.783234</td>\n",
              "      <td>0.149872</td>\n",
              "      <td>0.062020</td>\n",
              "      <td>0.135942</td>\n",
              "      <td>0.020582</td>\n",
              "      <td>0.449416</td>\n",
              "      <td>0.650412</td>\n",
              "      <td>0.617261</td>\n",
              "      <td>0.431165</td>\n",
              "      <td>0.687096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.678143</td>\n",
              "      <td>10.721868</td>\n",
              "      <td>10.743251</td>\n",
              "      <td>0.444057</td>\n",
              "      <td>0.495243</td>\n",
              "      <td>0.402165</td>\n",
              "      <td>0.276418</td>\n",
              "      <td>0.395060</td>\n",
              "      <td>0.498275</td>\n",
              "      <td>0.473516</td>\n",
              "      <td>0.454685</td>\n",
              "      <td>0.471361</td>\n",
              "      <td>0.193295</td>\n",
              "      <td>0.286264</td>\n",
              "      <td>0.348019</td>\n",
              "      <td>0.301523</td>\n",
              "      <td>0.186468</td>\n",
              "      <td>0.397777</td>\n",
              "      <td>0.393253</td>\n",
              "      <td>0.113443</td>\n",
              "      <td>0.351628</td>\n",
              "      <td>0.104150</td>\n",
              "      <td>0.28574</td>\n",
              "      <td>0.376596</td>\n",
              "      <td>0.072198</td>\n",
              "      <td>0.115515</td>\n",
              "      <td>0.153826</td>\n",
              "      <td>0.034887</td>\n",
              "      <td>0.325147</td>\n",
              "      <td>0.487677</td>\n",
              "      <td>0.403687</td>\n",
              "      <td>0.240097</td>\n",
              "      <td>0.19957</td>\n",
              "      <td>0.240320</td>\n",
              "      <td>0.281493</td>\n",
              "      <td>0.066089</td>\n",
              "      <td>0.210414</td>\n",
              "      <td>0.011038</td>\n",
              "      <td>0.131302</td>\n",
              "      <td>0.450391</td>\n",
              "      <td>0.333635</td>\n",
              "      <td>0.456340</td>\n",
              "      <td>0.412067</td>\n",
              "      <td>0.356968</td>\n",
              "      <td>0.241207</td>\n",
              "      <td>0.144729</td>\n",
              "      <td>0.016407</td>\n",
              "      <td>0.242194</td>\n",
              "      <td>0.201655</td>\n",
              "      <td>0.233309</td>\n",
              "      <td>0.227893</td>\n",
              "      <td>0.207827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034884</td>\n",
              "      <td>0.015038</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>22.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.081395</td>\n",
              "      <td>0.015038</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>33.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.174419</td>\n",
              "      <td>0.022556</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>42.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06dd08b3-8b09-4147-9293-1380a908a14e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06dd08b3-8b09-4147-9293-1380a908a14e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06dd08b3-8b09-4147-9293-1380a908a14e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Depression_Score  Anxiety_Score  Stress_Score  No_Degree  HighSchool   \n",
              "index                                                                         \n",
              "0                    13              6            12          0           1  \\\n",
              "1                     0              0             0          0           0   \n",
              "2                    14              2            14          0           1   \n",
              "3                     9              1             1          0           1   \n",
              "4                     0              1             0          0           1   \n",
              "...                 ...            ...           ...        ...         ...   \n",
              "8202                 42             39            42          0           0   \n",
              "8203                 28             28            31          1           0   \n",
              "8204                 42             33            40          0           0   \n",
              "8205                 42             34            39          1           0   \n",
              "8206                 15             21            30          1           0   \n",
              "\n",
              "       University  Graduate  Rual  Suburban  Urban  Male  Female   \n",
              "index                                                              \n",
              "0               0         0     0         0      1     0       1  \\\n",
              "1               1         0     0         1      0     1       0   \n",
              "2               0         0     1         0      0     1       0   \n",
              "3               0         0     0         0      1     0       1   \n",
              "4               0         0     0         1      0     1       0   \n",
              "...           ...       ...   ...       ...    ...   ...     ...   \n",
              "8202            1         0     0         0      1     0       1   \n",
              "8203            0         0     0         0      1     0       0   \n",
              "8204            0         1     0         1      0     0       1   \n",
              "8205            0         0     0         0      1     0       1   \n",
              "8206            0         0     0         1      0     0       1   \n",
              "\n",
              "       Other_Gender  Engnat  Right_h  Left_h  Ambidextrous  Agnostic  Atheist   \n",
              "index                                                                           \n",
              "0                 0       0        1       0             0         0        0  \\\n",
              "1                 0       1        1       0             0         1        0   \n",
              "2                 0       1        0       0             1         0        1   \n",
              "3                 0       1        1       0             0         1        0   \n",
              "4                 0       1        1       0             0         0        0   \n",
              "...             ...     ...      ...     ...           ...       ...      ...   \n",
              "8202              0       1        1       0             0         0        0   \n",
              "8203              1       1        1       0             0         0        1   \n",
              "8204              0       1        1       0             0         0        0   \n",
              "8205              0       1        1       0             0         1        0   \n",
              "8206              0       1        1       0             0         1        0   \n",
              "\n",
              "       Buddhist  Catholic  Mormon  Protestant  Other_Christian  Hindu  Jewish   \n",
              "index                                                                           \n",
              "0             0         1       0           0                0      0       0  \\\n",
              "1             0         0       0           0                0      0       0   \n",
              "2             0         0       0           0                0      0       0   \n",
              "3             0         0       0           0                0      0       0   \n",
              "4             0         0       0           0                1      0       0   \n",
              "...         ...       ...     ...         ...              ...    ...     ...   \n",
              "8202          0         0       0           0                1      0       0   \n",
              "8203          0         0       0           0                0      0       0   \n",
              "8204          0         1       0           0                0      0       0   \n",
              "8205          0         0       0           0                0      0       0   \n",
              "8206          0         0       0           0                0      0       0   \n",
              "\n",
              "       Muslim  Sikh  Other_Religion  Heterosexual  Bisexual  Homosexual   \n",
              "index                                                                     \n",
              "0           0     0               0             1         0           0  \\\n",
              "1           0     0               0             1         0           0   \n",
              "2           0     0               0             1         0           0   \n",
              "3           0     0               0             0         0           0   \n",
              "4           0     0               0             1         0           0   \n",
              "...       ...   ...             ...           ...       ...         ...   \n",
              "8202        0     0               0             1         0           0   \n",
              "8203        0     0               0             0         0           0   \n",
              "8204        0     0               0             1         0           0   \n",
              "8205        0     0               0             0         0           0   \n",
              "8206        0     0               0             1         0           0   \n",
              "\n",
              "       Asexual  Other_Orientation  Asian  Arab  Black  Indigenous_Australian   \n",
              "index                                                                          \n",
              "0            0                  0      0     0      0                      0  \\\n",
              "1            0                  0      0     0      0                      0   \n",
              "2            0                  0      0     0      0                      0   \n",
              "3            0                  1      0     0      0                      0   \n",
              "4            0                  0      0     0      1                      0   \n",
              "...        ...                ...    ...   ...    ...                    ...   \n",
              "8202         0                  0      1     0      0                      0   \n",
              "8203         1                  0      0     0      0                      0   \n",
              "8204         0                  0      0     0      0                      0   \n",
              "8205         0                  1      0     0      0                      0   \n",
              "8206         0                  0      0     0      0                      0   \n",
              "\n",
              "       Native_American  White  Other_Race  Voted  Never_married  Married   \n",
              "index                                                                      \n",
              "0                    0      0           1      0              1        0  \\\n",
              "1                    0      1           0      1              0        0   \n",
              "2                    0      1           0      0              1        0   \n",
              "3                    0      0           1      0              1        0   \n",
              "4                    0      0           0      0              1        0   \n",
              "...                ...    ...         ...    ...            ...      ...   \n",
              "8202                 0      0           0      1              1        0   \n",
              "8203                 0      0           1      0              1        0   \n",
              "8204                 0      1           0      1              0        1   \n",
              "8205                 0      1           0      0              1        0   \n",
              "8206                 0      0           1      0              1        0   \n",
              "\n",
              "       Previously_married       Age  FamilySize  Extraversion  Agreeableness   \n",
              "index                                                                          \n",
              "0                       0  0.081395    0.030075      0.214286       1.000000  \\\n",
              "1                       1  0.244186    0.015038      0.428571       0.428571   \n",
              "2                       0  0.069767    0.007519      0.357143       0.357143   \n",
              "3                       0  0.034884    0.022556      0.428571       0.714286   \n",
              "4                       0  0.058140    0.015038      0.857143       0.571429   \n",
              "...                   ...       ...         ...           ...            ...   \n",
              "8202                    0  0.104651    0.022556      0.142857       0.642857   \n",
              "8203                    0  0.058140    0.015038      0.357143       0.571429   \n",
              "8204                    0  0.383721    0.045113      0.357143       0.428571   \n",
              "8205                    0  0.011628    0.022556      0.428571       0.428571   \n",
              "8206                    0  0.034884    0.022556      0.785714       0.571429   \n",
              "\n",
              "       Conscientiousness  Emotional_Stability  Openness  \n",
              "index                                                    \n",
              "0               0.857143             0.928571  0.571429  \n",
              "1               0.857143             1.000000  0.857143  \n",
              "2               0.571429             0.928571  0.857143  \n",
              "3               0.571429             0.928571  0.571429  \n",
              "4               0.857143             0.928571  0.928571  \n",
              "...                  ...                  ...       ...  \n",
              "8202            0.142857             0.357143  0.785714  \n",
              "8203            0.714286             0.142857  0.642857  \n",
              "8204            0.857143             0.214286  0.642857  \n",
              "8205            0.214286             0.142857  0.357143  \n",
              "8206            0.714286             0.571429  0.500000  \n",
              "\n",
              "[8207 rows x 52 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa11d58e-38ca-42bb-8d57-d29737ac6650\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Depression_Score</th>\n",
              "      <th>Anxiety_Score</th>\n",
              "      <th>Stress_Score</th>\n",
              "      <th>No_Degree</th>\n",
              "      <th>HighSchool</th>\n",
              "      <th>University</th>\n",
              "      <th>Graduate</th>\n",
              "      <th>Rual</th>\n",
              "      <th>Suburban</th>\n",
              "      <th>Urban</th>\n",
              "      <th>Male</th>\n",
              "      <th>Female</th>\n",
              "      <th>Other_Gender</th>\n",
              "      <th>Engnat</th>\n",
              "      <th>Right_h</th>\n",
              "      <th>Left_h</th>\n",
              "      <th>Ambidextrous</th>\n",
              "      <th>Agnostic</th>\n",
              "      <th>Atheist</th>\n",
              "      <th>Buddhist</th>\n",
              "      <th>Catholic</th>\n",
              "      <th>Mormon</th>\n",
              "      <th>Protestant</th>\n",
              "      <th>Other_Christian</th>\n",
              "      <th>Hindu</th>\n",
              "      <th>Jewish</th>\n",
              "      <th>Muslim</th>\n",
              "      <th>Sikh</th>\n",
              "      <th>Other_Religion</th>\n",
              "      <th>Heterosexual</th>\n",
              "      <th>Bisexual</th>\n",
              "      <th>Homosexual</th>\n",
              "      <th>Asexual</th>\n",
              "      <th>Other_Orientation</th>\n",
              "      <th>Asian</th>\n",
              "      <th>Arab</th>\n",
              "      <th>Black</th>\n",
              "      <th>Indigenous_Australian</th>\n",
              "      <th>Native_American</th>\n",
              "      <th>White</th>\n",
              "      <th>Other_Race</th>\n",
              "      <th>Voted</th>\n",
              "      <th>Never_married</th>\n",
              "      <th>Married</th>\n",
              "      <th>Previously_married</th>\n",
              "      <th>Age</th>\n",
              "      <th>FamilySize</th>\n",
              "      <th>Extraversion</th>\n",
              "      <th>Agreeableness</th>\n",
              "      <th>Conscientiousness</th>\n",
              "      <th>Emotional_Stability</th>\n",
              "      <th>Openness</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.081395</td>\n",
              "      <td>0.030075</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.244186</td>\n",
              "      <td>0.015038</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.069767</td>\n",
              "      <td>0.007519</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.034884</td>\n",
              "      <td>0.022556</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.058140</td>\n",
              "      <td>0.015038</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.928571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8202</th>\n",
              "      <td>42</td>\n",
              "      <td>39</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.104651</td>\n",
              "      <td>0.022556</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.785714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8203</th>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.058140</td>\n",
              "      <td>0.015038</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.642857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8204</th>\n",
              "      <td>42</td>\n",
              "      <td>33</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.383721</td>\n",
              "      <td>0.045113</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.642857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8205</th>\n",
              "      <td>42</td>\n",
              "      <td>34</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011628</td>\n",
              "      <td>0.022556</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.357143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8206</th>\n",
              "      <td>15</td>\n",
              "      <td>21</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.034884</td>\n",
              "      <td>0.022556</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8207 rows × 52 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa11d58e-38ca-42bb-8d57-d29737ac6650')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa11d58e-38ca-42bb-8d57-d29737ac6650 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa11d58e-38ca-42bb-8d57-d29737ac6650');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Depression Model"
      ],
      "metadata": {
        "id": "cM2tmWsQVQ-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = Regressiondf[features]\n",
        "\n",
        "#Depression Model.\n",
        "D = Regressiondf[targets[0]]\n",
        "\n",
        "X_Regset, X_HoldRegset, D_Regset, D_HoldRegset = train_test_split(X, D, test_size=Holdout_size)"
      ],
      "metadata": {
        "id": "0D2kg4ojVPBI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32190ee1-c328-407a-ca57-9cb319dca4af"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 39.1 ms (2023-04-22T22:53:41/2023-04-22T22:53:41)</pre>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXgdfN2fYO-i"
      },
      "source": [
        "####K Neighbors Regressor Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "mURufTDvYPl9",
        "outputId": "89e352b7-eeed-436d-ae82-1be0a31df26b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 44.2 s (2023-04-22T22:53:41/2023-04-22T22:54:25)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy of the KNReg Model is: 15.771612973328054%\n",
            "{'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'distance'}\n"
          ]
        }
      ],
      "source": [
        "KNParaReg = {\n",
        "    'n_neighbors': [25,50,75],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    }\n",
        "\n",
        "KNReg = KNeighborsRegressor()\n",
        "DepRegModel1 = GridSearchCV(KNReg, KNParaReg)\n",
        "DepRegModel1.fit(X_Regset, D_Regset)\n",
        "\n",
        "DModel_Acc1 = DepRegModel1.score(X_HoldRegset, D_HoldRegset)\n",
        "\n",
        "print(f'The Accuracy of the KNReg Model is: {DModel_Acc1*100}%')\n",
        "print(DepRegModel1.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Random Forest Regression Model"
      ],
      "metadata": {
        "id": "-dvWxx7RpMyV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I spent my focus here since random forrest is both an esemble methoid and will better fit the categorical data."
      ],
      "metadata": {
        "id": "xO5JgQ1iE2GT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RFParaReg = {\n",
        "    'n_estimators':[29,30,33],\n",
        "    'criterion': ['squared_error', 'absolute_error'],\n",
        "    'max_depth': [5,6,7],\n",
        "    'min_samples_split': [19,20,23],\n",
        "    'random_state':[randnum]\n",
        "    }\n",
        "\n",
        "RFReg = RandomForestRegressor()\n",
        "DepRegModel2 = GridSearchCV(RFReg, RFParaReg)\n",
        "DepRegModel2.fit(X_Regset, D_Regset)\n",
        "\n",
        "DModel_Acc2 = DepRegModel2.score(X_HoldRegset, D_HoldRegset)\n",
        "\n",
        "print(f'The Accuracy of the RFReg Model is: {DModel_Acc2*100}%')\n",
        "print(DepRegModel2.best_params_)"
      ],
      "metadata": {
        "id": "uwQMjDZCPtg0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "537a7836-b57c-49f0-b96c-937cd39d17ec"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 45 min 28 s (2023-04-22T22:54:26/2023-04-22T23:39:54)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy of the RFReg Model is: 29.800301317187504%\n",
            "{'criterion': 'squared_error', 'max_depth': 7, 'min_samples_split': 20, 'n_estimators': 30, 'random_state': 500}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####History Gradient Boosting Regression Model"
      ],
      "metadata": {
        "id": "ubXFQB9R4iUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HGBParaReg = {\n",
        "    'loss':['squared_error', 'absolute_error'],\n",
        "    'learning_rate':[0.1,0.2, 0.3],\n",
        "    'max_iter':[125,150,175],\n",
        "    'max_depth':[2,3,4],\n",
        "    'random_state':[randnum],\n",
        "}\n",
        "\n",
        "HGBReg = HistGradientBoostingRegressor()\n",
        "DepRegModel3 = GridSearchCV(HGBReg, HGBParaReg)\n",
        "DepRegModel3.fit(X_Regset, D_Regset)\n",
        "\n",
        "DModel_Acc3 = DepRegModel3.score(X_HoldRegset, D_HoldRegset)\n",
        "\n",
        "print(f'The Accuracy of the HistGradientBoosting Model is: {DModel_Acc3*100}%')\n",
        "print(DepRegModel3.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "aR4-HcGZ4r4E",
        "outputId": "35d7c431-2dd9-446b-bcf2-c77407de516f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 2 min 50 s (2023-04-22T23:39:54/2023-04-22T23:42:45)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy of the HistGradientBoosting Model is: 31.271889650993522%\n",
            "{'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 2, 'max_iter': 175, 'random_state': 500}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awobaYn3BcJD"
      },
      "source": [
        "####Final Ensemble Methoid"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checks Which model has the greatest accuracy and puts it into an ensemble methoid to increase accuracy."
      ],
      "metadata": {
        "id": "YvXHN-3XBcJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ModelAccuracys = [DModel_Acc1, DModel_Acc2, DModel_Acc3]\n",
        "BestMod = max(ModelAccuracys)\n",
        "\n",
        "if BestMod == DModel_Acc1:\n",
        "  #The KNeighborsClassifier is the best model.\n",
        "  BestDepRegParams = DepRegModel1.best_params_\n",
        "\n",
        "  DepRegNei = BestDepRegParams['n_neighbors']\n",
        "  DepRegAlg = BestDepRegParams['algorithm']\n",
        "  DepRegWei = BestDepRegParams['weights']\n",
        "\n",
        "  FastDepRegMod = KNeighborsClassifier(n_neighbors=DepRegNei, algorithm=DepRegAlg, weights=DepRegWei, random_state=randnum)\n",
        "\n",
        "  FinalDepRegMod = BaggingRegressor(estimator=FastDepRegMod, n_estimators=50, random_state=randnum)\n",
        "  FinalDepRegMod.fit(X_Regset, D_Regset)\n",
        "\n",
        "  DRegMod_Acc = FinalDepRegMod.score(X_HoldRegset, D_HoldRegset)\n",
        "  print(f'The Accuracy of the KNeighbors Model is: {DRegMod_Acc*100}%')\n",
        "\n",
        "elif BestMod == DModel_Acc2:\n",
        "  #The Random Forest is the best model, but it's already an ensemble.\n",
        "  print(f'The Accuracy of the Random Forest Model is: {DModel_Acc2*100}%')\n",
        "\n",
        "elif BestMod == DModel_Acc3:\n",
        "  #The Random Forest is the best model, but it's already an ensemble.\n",
        "  print(f'The Accuracy of the HistGradientBoosting Model is: {DModel_Acc3*100}%')"
      ],
      "metadata": {
        "id": "QVNiUcsWBTsv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2d307557-6789-4a62-baab-02224ea581d9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 4.64 ms (2023-04-22T23:42:45/2023-04-22T23:42:45)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy of the HistGradientBoosting Model is: 31.271889650993522%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Anxiety Model"
      ],
      "metadata": {
        "id": "fSYPMPxnVY30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Anxiety Model.\n",
        "A = Regressiondf[targets[1]]\n",
        "randnum = 500\n",
        "\n",
        "X_Regset, X_HoldRegset, A_Regset, A_HoldRegset= train_test_split(X, A, test_size=Holdout_size)"
      ],
      "metadata": {
        "id": "6EqkYBt8Vd9F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abead202-4111-4bcd-beb3-5c9a9ad4f1af"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 17.5 ms (2023-04-22T23:42:45/2023-04-22T23:42:45)</pre>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz4ZqPeIZU3o"
      },
      "source": [
        "####K Neighbors Regressor Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "uAyJHtiAZU9n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c4741ee9-6341-4d57-b35f-0fe147e243c9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 1 min 4 s (2023-04-22T23:42:45/2023-04-22T23:43:50)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy of the KNReg Model is: 19.816140157414843%\n",
            "{'algorithm': 'kd_tree', 'n_neighbors': 250, 'weights': 'distance'}\n"
          ]
        }
      ],
      "source": [
        "KNParaReg = {\n",
        "    'n_neighbors': [250, 275, 300],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    }\n",
        "\n",
        "KNReg = KNeighborsRegressor()\n",
        "AnxRegModel1 = GridSearchCV(KNReg, KNParaReg)\n",
        "AnxRegModel1.fit(X_Regset, A_Regset)\n",
        "\n",
        "AModel_Acc1 = AnxRegModel1.score(X_HoldRegset, A_HoldRegset)\n",
        "\n",
        "print(f'The Accuracy of the KNReg Model is: {AModel_Acc1*100}%')\n",
        "print(AnxRegModel1.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Random Forest Regression Model"
      ],
      "metadata": {
        "id": "-gZ2J8YzawXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RFParaReg = {\n",
        "    'n_estimators':[27,30,32],\n",
        "    'criterion': ['squared_error', 'absolute_error'],\n",
        "    'max_depth': [7,8,9],\n",
        "    'min_samples_split': [+8,9,10],\n",
        "    'random_state':[randnum],\n",
        "    }\n",
        "\n",
        "RFReg = RandomForestRegressor()\n",
        "AnxRegModel2 = GridSearchCV(RFReg, RFParaReg)\n",
        "AnxRegModel2.fit(X_Regset, A_Regset)\n",
        "\n",
        "AModel_Acc2 = AnxRegModel2.score(X_HoldRegset, A_HoldRegset)\n",
        "\n",
        "print(f'The Accuracy of the RFReg Model is: {AModel_Acc2*100}%')\n",
        "print(AnxRegModel2.best_params_)"
      ],
      "metadata": {
        "id": "vFHHfRgMawXY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "35a052cd-1fea-4da6-9e8a-af9d59df9d5e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 48 min 11 s (2023-04-22T23:43:50/2023-04-23T00:32:02)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy of the RFReg Model is: 37.06923614354003%\n",
            "{'criterion': 'squared_error', 'max_depth': 8, 'min_samples_split': 8, 'n_estimators': 30, 'random_state': 500}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####History Gradient Boosting Regression Model"
      ],
      "metadata": {
        "id": "9UVXrkGd6Gqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HGBParaReg = {\n",
        "    'loss':['squared_error', 'absolute_error'],\n",
        "    'learning_rate':[0.2,0.3,0.4],\n",
        "    'max_iter':[10,25,50,75],\n",
        "    'max_depth':[2,5,7],\n",
        "    'random_state':[randnum],\n",
        "}\n",
        "\n",
        "HGBReg = HistGradientBoostingRegressor()\n",
        "AnxRegModel3 = GridSearchCV(HGBReg, HGBParaReg)\n",
        "AnxRegModel3.fit(X_Regset, A_Regset)\n",
        "\n",
        "AModel_Acc3 = AnxRegModel3.score(X_HoldRegset, A_HoldRegset)\n",
        "\n",
        "print(f'The Accuracy of the HistGradientBoosting Model is: {AModel_Acc3*100}%')\n",
        "print(AnxRegModel3.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "gxdxWOzl6Gqz",
        "outputId": "d3259786-ffdc-46ee-f29b-4045315e607a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 2 min (2023-04-23T00:32:02/2023-04-23T00:34:02)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy of the HistGradientBoosting Model is: 39.276840353249376%\n",
            "{'learning_rate': 0.2, 'loss': 'squared_error', 'max_depth': 2, 'max_iter': 75, 'random_state': 500}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90NsXxBFawXZ"
      },
      "source": [
        "####Final Ensemble Methoid"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checks Which model has the greatest accuracy and puts it into an ensemble methoid to increase accuracy."
      ],
      "metadata": {
        "id": "bynBzRhsawXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ModelAccuracys = [AModel_Acc1, AModel_Acc2, AModel_Acc3]\n",
        "BestMod = max(ModelAccuracys)\n",
        "\n",
        "if BestMod == DModel_Acc1:\n",
        "  #The KNeighborsClassifier is the best model.\n",
        "  BestAnxRegParams = AnxRegModel1.best_params_\n",
        "\n",
        "  AnxRegNei = BestAnxRegParams['n_neighbors']\n",
        "  AnxRegAlg = BestAnxRegParams['algorithm']\n",
        "  AnxRegWei = BestAnxRegParams['weights']\n",
        "\n",
        "  FastAnxRegMod = KNeighborsClassifier(n_neighbors=AnxRegNei, algorithm=AnxRegAlg, weights=AnxRegWei, random_state=randnum)\n",
        "\n",
        "  FinalAnxRegMod = BaggingRegressor(estimator=FastAnxRegMod, n_estimators=50, random_state=randnum)\n",
        "  FinalAnxRegMod.fit(X_Regset, A_Regset)\n",
        "\n",
        "  ARegMod_Acc = FinalAnxRegMod.score(X_HoldRegset, A_HoldRegset)\n",
        "  print(f'The Accuracy of the KNeighbors Model is: {ARegMod_Acc*100}%')\n",
        "\n",
        "elif BestMod == AModel_Acc2:\n",
        "  #The Random Forest is the best model, but it's already an ensemble.\n",
        "  print(f'The Accuracy of the Random Forest Model is: {AModel_Acc2*100}%')\n",
        "\n",
        "elif BestMod == AModel_Acc3:\n",
        "  #The Random Forest is the best model, but it's already an ensemble.\n",
        "  print(f'The Accuracy of the HistGradientBoosting Model is: {AModel_Acc3*100}%')"
      ],
      "metadata": {
        "id": "kuwFDHDcawXZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "890b4525-2384-4e9c-ef53-0e48d4f1c473"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 3.14 ms (2023-04-23T00:34:02/2023-04-23T00:34:02)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy of the HistGradientBoosting Model is: 39.276840353249376%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Stress Model"
      ],
      "metadata": {
        "id": "R9Rfe78eVeZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "S = Regressiondf[targets[2]]\n",
        "\n",
        "X_Regset, X_HoldRegset, S_Regset, S_HoldRegset = train_test_split(X, S, test_size=Holdout_size)"
      ],
      "metadata": {
        "id": "DQ_GxFbXVhnD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b4550ed-d7cc-4fcb-d379-0e6ccc9150da"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 21.6 ms (2023-04-23T00:34:03/2023-04-23T00:34:03)</pre>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Klj14ZxLZ_tr"
      },
      "source": [
        "####K Neighbors Regressor Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "6MJAvIVxaA1t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "230aa32e-c4b4-4638-fd53-faa1a315f645"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 46.4 s (2023-04-23T00:34:03/2023-04-23T00:34:49)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy of the KNReg Model is: 19.218215456813937%\n",
            "{'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'distance'}\n"
          ]
        }
      ],
      "source": [
        "KNParaReg = {\n",
        "    'n_neighbors': [25, 50, 75],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    }\n",
        "\n",
        "KNReg = KNeighborsRegressor()\n",
        "StsRegMod1 = GridSearchCV(KNReg, KNParaReg)\n",
        "StsRegMod1.fit(X_Regset, S_Regset)\n",
        "\n",
        "SModel_Acc1 = StsRegMod1.score(X_HoldRegset, S_HoldRegset)\n",
        "\n",
        "print(f'The Accuracy of the KNReg Model is: {SModel_Acc1*100}%')\n",
        "print(StsRegMod1.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Random Forest Regression Model"
      ],
      "metadata": {
        "id": "KWboEvpua0yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RFParaReg = {\n",
        "    'n_estimators':[10,20,30],\n",
        "    'criterion': ['squared_error', 'absolute_error'],\n",
        "    'max_depth': [8,9,10],\n",
        "    'min_samples_split': [9,10,13,15],\n",
        "    'random_state':[randnum],\n",
        "    }\n",
        "\n",
        "RFReg = RandomForestRegressor()\n",
        "StsRegMod2 = GridSearchCV(RFReg, RFParaReg)\n",
        "StsRegMod2.fit(X_Regset, S_Regset)\n",
        "\n",
        "SModel_Acc2 = StsRegMod2.score(X_HoldRegset, S_HoldRegset)\n",
        "\n",
        "print(f'The Accuracy of the RFReg Model is: {SModel_Acc2*100}%')\n",
        "print(StsRegMod2.best_params_)"
      ],
      "metadata": {
        "id": "Qx0X65ZVa0yx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "df0ab82b-a761-472a-c4a6-e6493c5fc2c7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 46 min 3 s (2023-04-23T00:34:49/2023-04-23T01:20:53)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy of the RFReg Model is: 43.823952046564365%\n",
            "{'criterion': 'squared_error', 'max_depth': 8, 'min_samples_split': 15, 'n_estimators': 30, 'random_state': 500}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####History Gradient Boosting Regression Model"
      ],
      "metadata": {
        "id": "PBszTAQs6kie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HGBParaReg = {\n",
        "    'loss':['squared_error', 'absolute_error', 'poisson', 'quantile'],\n",
        "    'learning_rate':[0.1,0.3,0.5,0.7,0.9],\n",
        "    'max_iter':[75,100,150,200],\n",
        "    'max_depth':[2,5,7],\n",
        "    'random_state':[randnum],\n",
        "}\n",
        "\n",
        "HGBReg = HistGradientBoostingRegressor()\n",
        "StsRegModel3 = GridSearchCV(HGBReg, HGBParaReg)\n",
        "StsRegModel3.fit(X_Regset, S_Regset)\n",
        "\n",
        "SModel_Acc3 = StsRegModel3.score(X_HoldRegset, S_HoldRegset)\n",
        "\n",
        "print(f'The Accuracy of the HistGradientBoosting Model is: {SModel_Acc3*100}%')\n",
        "print(StsRegModel3.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5FwYsPkJ6kie",
        "outputId": "f45e0e52-065d-46d2-aae0-2e5288839a4c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 13 min 36 s (2023-04-23T01:20:53/2023-04-23T01:34:29)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "300 fits failed out of a total of 1200.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "300 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 407, in fit\n",
            "    self._loss = self._get_loss(sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\", line 1524, in _get_loss\n",
            "    return _LOSSES[self.loss](\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/_loss/loss.py\", line 610, in __init__\n",
            "    check_scalar(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\", line 1498, in check_scalar\n",
            "    raise TypeError(\n",
            "TypeError: quantile must be an instance of float, not NoneType.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [ 0.45351215  0.45566426  0.45686753  0.45678822  0.44831155  0.4447364\n",
            "  0.43905601  0.43220964  0.44276033  0.43758304  0.42870348  0.4182361\n",
            "  0.44851179  0.44909012  0.44960094  0.44897827  0.44887287  0.44726118\n",
            "  0.44389018  0.4413774   0.44588963  0.44379368  0.44029111  0.43653543\n",
            "  0.45179924  0.45395124  0.45420911  0.45368651  0.44801939  0.4441816\n",
            "  0.43664032  0.4305044   0.44274351  0.43722608  0.42676479  0.4180349\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "  0.45430487  0.45507812  0.45019995  0.44761344  0.41765783  0.40596267\n",
            "  0.38668671  0.37016131  0.39619919  0.38062816  0.35855073  0.33924028\n",
            "  0.44513752  0.44369861  0.44200955  0.44107424  0.42911233  0.42622919\n",
            "  0.42096556  0.41619127  0.42061009  0.41270277  0.40541345  0.40226072\n",
            "  0.45163866  0.45038198  0.44628909  0.44355875  0.41162752  0.40396755\n",
            "  0.37940255  0.36202455  0.39561433  0.37992972  0.35509209  0.33190607\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "  0.44487596  0.44307608  0.43754479  0.43316726  0.35839747  0.33976815\n",
            "  0.31305543  0.29090393  0.32358376  0.30474749  0.27954215  0.2649367\n",
            "  0.44018019  0.43640287  0.43284616  0.43142232  0.40462576  0.39882476\n",
            "  0.39085038  0.38448232  0.3854167   0.37844418  0.37036555  0.36416982\n",
            "  0.445071    0.44285261  0.43707991  0.43017156  0.35874222  0.33003913\n",
            "  0.29081668  0.26514863  0.31268376  0.28756908  0.26320439  0.23880321\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "  0.43708853  0.43183983  0.42581459  0.41991668  0.30845781  0.28225866\n",
            "  0.2435226   0.21651913  0.24975961  0.22467404  0.1942289   0.18133051\n",
            "  0.4315478   0.4310712   0.42501595  0.42411879  0.36663776  0.36026112\n",
            "  0.35312825  0.34633025  0.34420726  0.33777578  0.32948149  0.32453004\n",
            "  0.43203086  0.42756546  0.42189241  0.41253576  0.29636908  0.26736374\n",
            "  0.21019709  0.18158258  0.23194944  0.20456774  0.17238518  0.14690523\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "  0.42040021  0.40921257  0.40361997  0.39617311  0.23168296  0.19487841\n",
            "  0.14243554  0.11539445  0.16112138  0.13175067  0.10032564  0.08208049\n",
            "  0.42080682  0.42055956  0.41549615  0.41241302  0.32933061  0.32227328\n",
            "  0.31088668  0.3026106   0.29199917  0.28623395  0.27861534  0.27357925\n",
            "  0.42154903  0.41759248  0.40291985  0.38963296  0.19371453  0.1489403\n",
            "  0.09081455  0.04608494  0.10737661  0.07534794  0.01832829 -0.01023183\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy of the HistGradientBoosting Model is: 45.45948507503227%\n",
            "{'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 2, 'max_iter': 150, 'random_state': 500}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bizRVBha0yx"
      },
      "source": [
        "####Final Ensemble Methoid"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checks Which model has the greatest accuracy and puts it into an ensemble methoid to increase accuracy."
      ],
      "metadata": {
        "id": "dK9-G7Zoa0yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ModelAccuracys = [SModel_Acc1, SModel_Acc2, SModel_Acc3]\n",
        "BestMod = max(ModelAccuracys)\n",
        "\n",
        "if BestMod == SModel_Acc1:\n",
        "  #The KNeighborsClassifier is the best model.\n",
        "  BestStsRegParams = StsRegMod1.best_params_\n",
        "\n",
        "  StsRegNei = BestStsRegParams['n_neighbors']\n",
        "  StsRegAlg = BestStsRegParams['algorithm']\n",
        "  StsRegWei = BestStsRegParams['weights']\n",
        "\n",
        "  FastStsRegMod = KNeighborsRegressor(n_neighbors=StsRegNei, algorithm=StsRegAlg, weights=StsRegWei, random_state=randnum)\n",
        "\n",
        "  FinalStsRegMod = BaggingRegressor(estimator=FastStsRegMod, n_estimators=50, random_state=randnum)\n",
        "  FinalStsRegMod.fit(X_Regset, S_Regset)\n",
        "\n",
        "  SRegMod_Acc = FinalStsRegMod.score(X_HoldRegset, S_HoldRegset)\n",
        "  print(f'The Accuracy of the KNeighbors Model is: {SRegMod_Acc*100}%')\n",
        "\n",
        "elif BestMod == SModel_Acc2:\n",
        "  #The Random Forest is the best model, but it's already an ensemble.\n",
        "  print(f'The Accuracy of the Random Forest Model is: {SModel_Acc2*100}%')\n",
        "\n",
        "elif BestMod == SModel_Acc3:\n",
        "  #The Random Forest is the best model, but it's already an ensemble.\n",
        "  print(f'The Accuracy of the HistGradientBoosting Model is: {SModel_Acc3*100}%')"
      ],
      "metadata": {
        "id": "I1KPVntxa0yx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ddd1652d-219e-48b7-d60d-a8dcb59bd279"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 1.75 ms (2023-04-23T01:34:29/2023-04-23T01:34:29)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy of the HistGradientBoosting Model is: 45.45948507503227%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Clssification Approach"
      ],
      "metadata": {
        "id": "R9ML79I2ZZ9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Classdf = Modeldf\n",
        "#Changes the target scores to match the target classes for Classification.\n",
        "#Grabs the location of the target columns.\n",
        "Dloc = Classdf.columns.get_loc('Depression_Score')\n",
        "Aloc = Classdf.columns.get_loc('Anxiety_Score')\n",
        "Sloc = Classdf.columns.get_loc('Stress_Score')\n",
        "\n",
        "for i in range(len(Classdf)):\n",
        "  #Depression.\n",
        "  if Classdf.iat[i,Dloc] <= 9:\n",
        "    Classdf.iat[i,Dloc] = 0\n",
        "\n",
        "  elif Classdf.iat[i,Dloc] <= 13:\n",
        "    Classdf.iat[i,Dloc] = 1\n",
        "\n",
        "  elif Classdf.iat[i,Dloc] <= 20:\n",
        "    Classdf.iat[i,Dloc] = 2\n",
        "\n",
        "  elif Classdf.iat[i,Dloc] <= 27:\n",
        "    Classdf.iat[i,Dloc] = 3\n",
        "\n",
        "  elif Classdf.iat[i,Dloc] >= 28:\n",
        "    Classdf.iat[i,Dloc] = 4\n",
        "\n",
        "  #Anxeity.\n",
        "  if Classdf.iat[i,Aloc] <= 7:\n",
        "    Classdf.iat[i,Aloc] = 0\n",
        "\n",
        "  elif Classdf.iat[i,Aloc] <= 9:\n",
        "    Classdf.iat[i,Aloc] = 1\n",
        "\n",
        "  elif Classdf.iat[i,Aloc] <= 14:\n",
        "    Classdf.iat[i,Aloc] = 2\n",
        "\n",
        "  elif Classdf.iat[i,Aloc] <= 19:\n",
        "    Classdf.iat[i,Aloc] = 3\n",
        "\n",
        "  elif Classdf.iat[i,Aloc] >= 20:\n",
        "    Classdf.iat[i,Aloc] = 4\n",
        "\n",
        "  #Stress.\n",
        "  if Classdf.iat[i,Sloc] <= 14:\n",
        "    Classdf.iat[i,Sloc] = 0\n",
        "\n",
        "  elif Classdf.iat[i,Sloc] <= 18:\n",
        "    Classdf.iat[i,Sloc] = 1\n",
        "\n",
        "  elif Classdf.iat[i,Sloc] <= 25:\n",
        "    Classdf.iat[i,Sloc] = 2\n",
        "\n",
        "  elif Classdf.iat[i,Sloc] <= 33:\n",
        "    Classdf.iat[i,Sloc] = 3\n",
        "\n",
        "  elif Classdf.iat[i,Sloc] >= 34:\n",
        "    Classdf.iat[i,Sloc] = 4"
      ],
      "metadata": {
        "id": "hTvg1NNdfCvr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2af2d049-6440-45c2-e3aa-4171b15669be"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 3.34 s (2023-04-23T01:47:45/2023-04-23T01:47:48)</pre>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Examining the Data before Classification"
      ],
      "metadata": {
        "id": "9U6PAiVncUZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification Data is checked and verified that all preprocessing steps executed correctly."
      ],
      "metadata": {
        "id": "OXxiSh4U2Dgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(Classdf.describe(include='all'))\n",
        "ut.pprint(Classdf)\n",
        "\n",
        "print(np.sum(Classdf[['Depression_Score']] == 4))"
      ],
      "metadata": {
        "id": "kltiyKXQcT6j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "outputId": "c2ab8108-3ee3-479d-cb7e-fd4e1795177d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 367 ms (2023-04-23T01:47:48/2023-04-23T01:47:49)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Depression_Score  Anxiety_Score  Stress_Score    No_Degree   \n",
              "count            8207.0         8207.0        8207.0  8207.000000  \\\n",
              "mean           2.411478        2.23943      1.915438     0.270135   \n",
              "std            1.561145       1.625208      1.444957     0.444057   \n",
              "min                 0.0            0.0           0.0     0.000000   \n",
              "25%                 1.0            0.0           0.0     0.000000   \n",
              "50%                 3.0            2.0           2.0     0.000000   \n",
              "75%                 4.0            4.0           3.0     1.000000   \n",
              "max                 4.0            4.0           4.0     1.000000   \n",
              "\n",
              "        HighSchool   University     Graduate         Rual     Suburban   \n",
              "count  8207.000000  8207.000000  8207.000000  8207.000000  8207.000000  \\\n",
              "mean      0.430974     0.202876     0.083343     0.193493     0.458145   \n",
              "std       0.495243     0.402165     0.276418     0.395060     0.498275   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       1.000000     0.000000     0.000000     0.000000     1.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "             Urban         Male       Female  Other_Gender       Engnat   \n",
              "count  8207.000000  8207.000000  8207.000000   8207.000000  8207.000000  \\\n",
              "mean      0.339344     0.291946     0.666870      0.038869     0.909955   \n",
              "std       0.473516     0.454685     0.471361      0.193295     0.286264   \n",
              "min       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000      0.000000     1.000000   \n",
              "50%       0.000000     0.000000     1.000000      0.000000     1.000000   \n",
              "75%       1.000000     1.000000     1.000000      0.000000     1.000000   \n",
              "max       1.000000     1.000000     1.000000      1.000000     1.000000   \n",
              "\n",
              "           Right_h       Left_h  Ambidextrous     Agnostic      Atheist   \n",
              "count  8207.000000  8207.000000   8207.000000  8207.000000  8207.000000  \\\n",
              "mean      0.859023     0.101133      0.036067     0.197027     0.191178   \n",
              "std       0.348019     0.301523      0.186468     0.397777     0.393253   \n",
              "min       0.000000     0.000000      0.000000     0.000000     0.000000   \n",
              "25%       1.000000     0.000000      0.000000     0.000000     0.000000   \n",
              "50%       1.000000     0.000000      0.000000     0.000000     0.000000   \n",
              "75%       1.000000     0.000000      0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000      1.000000     1.000000     1.000000   \n",
              "\n",
              "          Buddhist     Catholic       Mormon  Protestant  Other_Christian   \n",
              "count  8207.000000  8207.000000  8207.000000  8207.00000      8207.000000  \\\n",
              "mean      0.013038     0.144511     0.010966     0.08968         0.171073   \n",
              "std       0.113443     0.351628     0.104150     0.28574         0.376596   \n",
              "min       0.000000     0.000000     0.000000     0.00000         0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.00000         0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.00000         0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.00000         0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.00000         1.000000   \n",
              "\n",
              "             Hindu       Jewish       Muslim         Sikh  Other_Religion   \n",
              "count  8207.000000  8207.000000  8207.000000  8207.000000     8207.000000  \\\n",
              "mean      0.005239     0.013525     0.024248     0.001218        0.120141   \n",
              "std       0.072198     0.115515     0.153826     0.034887        0.325147   \n",
              "min       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000        1.000000   \n",
              "\n",
              "       Heterosexual     Bisexual   Homosexual     Asexual  Other_Orientation   \n",
              "count   8207.000000  8207.000000  8207.000000  8207.00000        8207.000000  \\\n",
              "mean       0.610454     0.204947     0.061411     0.04155           0.061533   \n",
              "std        0.487677     0.403687     0.240097     0.19957           0.240320   \n",
              "min        0.000000     0.000000     0.000000     0.00000           0.000000   \n",
              "25%        0.000000     0.000000     0.000000     0.00000           0.000000   \n",
              "50%        1.000000     0.000000     0.000000     0.00000           0.000000   \n",
              "75%        1.000000     0.000000     0.000000     0.00000           0.000000   \n",
              "max        1.000000     1.000000     1.000000     1.00000           1.000000   \n",
              "\n",
              "             Asian         Arab        Black  Indigenous_Australian   \n",
              "count  8207.000000  8207.000000  8207.000000            8207.000000  \\\n",
              "mean      0.086755     0.004386     0.046424               0.000122   \n",
              "std       0.281493     0.066089     0.210414               0.011038   \n",
              "min       0.000000     0.000000     0.000000               0.000000   \n",
              "25%       0.000000     0.000000     0.000000               0.000000   \n",
              "50%       0.000000     0.000000     0.000000               0.000000   \n",
              "75%       0.000000     0.000000     0.000000               0.000000   \n",
              "max       1.000000     1.000000     1.000000               1.000000   \n",
              "\n",
              "       Native_American        White   Other_Race        Voted  Never_married   \n",
              "count      8207.000000  8207.000000  8207.000000  8207.000000    8207.000000  \\\n",
              "mean          0.017546     0.717193     0.127574     0.295601       0.783234   \n",
              "std           0.131302     0.450391     0.333635     0.456340       0.412067   \n",
              "min           0.000000     0.000000     0.000000     0.000000       0.000000   \n",
              "25%           0.000000     0.000000     0.000000     0.000000       1.000000   \n",
              "50%           0.000000     1.000000     0.000000     0.000000       1.000000   \n",
              "75%           0.000000     1.000000     0.000000     1.000000       1.000000   \n",
              "max           1.000000     1.000000     1.000000     1.000000       1.000000   \n",
              "\n",
              "           Married  Previously_married          Age   FamilySize   \n",
              "count  8207.000000         8207.000000  8207.000000  8207.000000  \\\n",
              "mean      0.149872            0.062020     0.135942     0.020582   \n",
              "std       0.356968            0.241207     0.144729     0.016407   \n",
              "min       0.000000            0.000000     0.000000     0.000000   \n",
              "25%       0.000000            0.000000     0.034884     0.015038   \n",
              "50%       0.000000            0.000000     0.081395     0.015038   \n",
              "75%       0.000000            0.000000     0.174419     0.022556   \n",
              "max       1.000000            1.000000     1.000000     1.000000   \n",
              "\n",
              "       Extraversion  Agreeableness  Conscientiousness  Emotional_Stability   \n",
              "count   8207.000000    8207.000000        8207.000000          8207.000000  \\\n",
              "mean       0.449416       0.650412           0.617261             0.431165   \n",
              "std        0.242194       0.201655           0.233309             0.227893   \n",
              "min        0.000000       0.000000           0.000000             0.000000   \n",
              "25%        0.214286       0.500000           0.428571             0.285714   \n",
              "50%        0.428571       0.642857           0.642857             0.357143   \n",
              "75%        0.642857       0.785714           0.785714             0.571429   \n",
              "max        1.000000       1.000000           1.000000             1.000000   \n",
              "\n",
              "          Openness  \n",
              "count  8207.000000  \n",
              "mean      0.687096  \n",
              "std       0.207827  \n",
              "min       0.000000  \n",
              "25%       0.571429  \n",
              "50%       0.714286  \n",
              "75%       0.857143  \n",
              "max       1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbf85fa4-17f5-4875-8ad9-e4be24d78530\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Depression_Score</th>\n",
              "      <th>Anxiety_Score</th>\n",
              "      <th>Stress_Score</th>\n",
              "      <th>No_Degree</th>\n",
              "      <th>HighSchool</th>\n",
              "      <th>University</th>\n",
              "      <th>Graduate</th>\n",
              "      <th>Rual</th>\n",
              "      <th>Suburban</th>\n",
              "      <th>Urban</th>\n",
              "      <th>Male</th>\n",
              "      <th>Female</th>\n",
              "      <th>Other_Gender</th>\n",
              "      <th>Engnat</th>\n",
              "      <th>Right_h</th>\n",
              "      <th>Left_h</th>\n",
              "      <th>Ambidextrous</th>\n",
              "      <th>Agnostic</th>\n",
              "      <th>Atheist</th>\n",
              "      <th>Buddhist</th>\n",
              "      <th>Catholic</th>\n",
              "      <th>Mormon</th>\n",
              "      <th>Protestant</th>\n",
              "      <th>Other_Christian</th>\n",
              "      <th>Hindu</th>\n",
              "      <th>Jewish</th>\n",
              "      <th>Muslim</th>\n",
              "      <th>Sikh</th>\n",
              "      <th>Other_Religion</th>\n",
              "      <th>Heterosexual</th>\n",
              "      <th>Bisexual</th>\n",
              "      <th>Homosexual</th>\n",
              "      <th>Asexual</th>\n",
              "      <th>Other_Orientation</th>\n",
              "      <th>Asian</th>\n",
              "      <th>Arab</th>\n",
              "      <th>Black</th>\n",
              "      <th>Indigenous_Australian</th>\n",
              "      <th>Native_American</th>\n",
              "      <th>White</th>\n",
              "      <th>Other_Race</th>\n",
              "      <th>Voted</th>\n",
              "      <th>Never_married</th>\n",
              "      <th>Married</th>\n",
              "      <th>Previously_married</th>\n",
              "      <th>Age</th>\n",
              "      <th>FamilySize</th>\n",
              "      <th>Extraversion</th>\n",
              "      <th>Agreeableness</th>\n",
              "      <th>Conscientiousness</th>\n",
              "      <th>Emotional_Stability</th>\n",
              "      <th>Openness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8207.0</td>\n",
              "      <td>8207.0</td>\n",
              "      <td>8207.0</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.00000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.00000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "      <td>8207.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.411478</td>\n",
              "      <td>2.23943</td>\n",
              "      <td>1.915438</td>\n",
              "      <td>0.270135</td>\n",
              "      <td>0.430974</td>\n",
              "      <td>0.202876</td>\n",
              "      <td>0.083343</td>\n",
              "      <td>0.193493</td>\n",
              "      <td>0.458145</td>\n",
              "      <td>0.339344</td>\n",
              "      <td>0.291946</td>\n",
              "      <td>0.666870</td>\n",
              "      <td>0.038869</td>\n",
              "      <td>0.909955</td>\n",
              "      <td>0.859023</td>\n",
              "      <td>0.101133</td>\n",
              "      <td>0.036067</td>\n",
              "      <td>0.197027</td>\n",
              "      <td>0.191178</td>\n",
              "      <td>0.013038</td>\n",
              "      <td>0.144511</td>\n",
              "      <td>0.010966</td>\n",
              "      <td>0.08968</td>\n",
              "      <td>0.171073</td>\n",
              "      <td>0.005239</td>\n",
              "      <td>0.013525</td>\n",
              "      <td>0.024248</td>\n",
              "      <td>0.001218</td>\n",
              "      <td>0.120141</td>\n",
              "      <td>0.610454</td>\n",
              "      <td>0.204947</td>\n",
              "      <td>0.061411</td>\n",
              "      <td>0.04155</td>\n",
              "      <td>0.061533</td>\n",
              "      <td>0.086755</td>\n",
              "      <td>0.004386</td>\n",
              "      <td>0.046424</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>0.017546</td>\n",
              "      <td>0.717193</td>\n",
              "      <td>0.127574</td>\n",
              "      <td>0.295601</td>\n",
              "      <td>0.783234</td>\n",
              "      <td>0.149872</td>\n",
              "      <td>0.062020</td>\n",
              "      <td>0.135942</td>\n",
              "      <td>0.020582</td>\n",
              "      <td>0.449416</td>\n",
              "      <td>0.650412</td>\n",
              "      <td>0.617261</td>\n",
              "      <td>0.431165</td>\n",
              "      <td>0.687096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.561145</td>\n",
              "      <td>1.625208</td>\n",
              "      <td>1.444957</td>\n",
              "      <td>0.444057</td>\n",
              "      <td>0.495243</td>\n",
              "      <td>0.402165</td>\n",
              "      <td>0.276418</td>\n",
              "      <td>0.395060</td>\n",
              "      <td>0.498275</td>\n",
              "      <td>0.473516</td>\n",
              "      <td>0.454685</td>\n",
              "      <td>0.471361</td>\n",
              "      <td>0.193295</td>\n",
              "      <td>0.286264</td>\n",
              "      <td>0.348019</td>\n",
              "      <td>0.301523</td>\n",
              "      <td>0.186468</td>\n",
              "      <td>0.397777</td>\n",
              "      <td>0.393253</td>\n",
              "      <td>0.113443</td>\n",
              "      <td>0.351628</td>\n",
              "      <td>0.104150</td>\n",
              "      <td>0.28574</td>\n",
              "      <td>0.376596</td>\n",
              "      <td>0.072198</td>\n",
              "      <td>0.115515</td>\n",
              "      <td>0.153826</td>\n",
              "      <td>0.034887</td>\n",
              "      <td>0.325147</td>\n",
              "      <td>0.487677</td>\n",
              "      <td>0.403687</td>\n",
              "      <td>0.240097</td>\n",
              "      <td>0.19957</td>\n",
              "      <td>0.240320</td>\n",
              "      <td>0.281493</td>\n",
              "      <td>0.066089</td>\n",
              "      <td>0.210414</td>\n",
              "      <td>0.011038</td>\n",
              "      <td>0.131302</td>\n",
              "      <td>0.450391</td>\n",
              "      <td>0.333635</td>\n",
              "      <td>0.456340</td>\n",
              "      <td>0.412067</td>\n",
              "      <td>0.356968</td>\n",
              "      <td>0.241207</td>\n",
              "      <td>0.144729</td>\n",
              "      <td>0.016407</td>\n",
              "      <td>0.242194</td>\n",
              "      <td>0.201655</td>\n",
              "      <td>0.233309</td>\n",
              "      <td>0.227893</td>\n",
              "      <td>0.207827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034884</td>\n",
              "      <td>0.015038</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.081395</td>\n",
              "      <td>0.015038</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.174419</td>\n",
              "      <td>0.022556</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbf85fa4-17f5-4875-8ad9-e4be24d78530')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cbf85fa4-17f5-4875-8ad9-e4be24d78530 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cbf85fa4-17f5-4875-8ad9-e4be24d78530');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Depression_Score  Anxiety_Score  Stress_Score  No_Degree  HighSchool   \n",
              "index                                                                         \n",
              "0                     1              0             0          0           1  \\\n",
              "1                     0              0             0          0           0   \n",
              "2                     2              0             0          0           1   \n",
              "3                     0              0             0          0           1   \n",
              "4                     0              0             0          0           1   \n",
              "...                 ...            ...           ...        ...         ...   \n",
              "8202                  4              4             4          0           0   \n",
              "8203                  4              4             3          1           0   \n",
              "8204                  4              4             4          0           0   \n",
              "8205                  4              4             4          1           0   \n",
              "8206                  2              4             3          1           0   \n",
              "\n",
              "       University  Graduate  Rual  Suburban  Urban  Male  Female   \n",
              "index                                                              \n",
              "0               0         0     0         0      1     0       1  \\\n",
              "1               1         0     0         1      0     1       0   \n",
              "2               0         0     1         0      0     1       0   \n",
              "3               0         0     0         0      1     0       1   \n",
              "4               0         0     0         1      0     1       0   \n",
              "...           ...       ...   ...       ...    ...   ...     ...   \n",
              "8202            1         0     0         0      1     0       1   \n",
              "8203            0         0     0         0      1     0       0   \n",
              "8204            0         1     0         1      0     0       1   \n",
              "8205            0         0     0         0      1     0       1   \n",
              "8206            0         0     0         1      0     0       1   \n",
              "\n",
              "       Other_Gender  Engnat  Right_h  Left_h  Ambidextrous  Agnostic  Atheist   \n",
              "index                                                                           \n",
              "0                 0       0        1       0             0         0        0  \\\n",
              "1                 0       1        1       0             0         1        0   \n",
              "2                 0       1        0       0             1         0        1   \n",
              "3                 0       1        1       0             0         1        0   \n",
              "4                 0       1        1       0             0         0        0   \n",
              "...             ...     ...      ...     ...           ...       ...      ...   \n",
              "8202              0       1        1       0             0         0        0   \n",
              "8203              1       1        1       0             0         0        1   \n",
              "8204              0       1        1       0             0         0        0   \n",
              "8205              0       1        1       0             0         1        0   \n",
              "8206              0       1        1       0             0         1        0   \n",
              "\n",
              "       Buddhist  Catholic  Mormon  Protestant  Other_Christian  Hindu  Jewish   \n",
              "index                                                                           \n",
              "0             0         1       0           0                0      0       0  \\\n",
              "1             0         0       0           0                0      0       0   \n",
              "2             0         0       0           0                0      0       0   \n",
              "3             0         0       0           0                0      0       0   \n",
              "4             0         0       0           0                1      0       0   \n",
              "...         ...       ...     ...         ...              ...    ...     ...   \n",
              "8202          0         0       0           0                1      0       0   \n",
              "8203          0         0       0           0                0      0       0   \n",
              "8204          0         1       0           0                0      0       0   \n",
              "8205          0         0       0           0                0      0       0   \n",
              "8206          0         0       0           0                0      0       0   \n",
              "\n",
              "       Muslim  Sikh  Other_Religion  Heterosexual  Bisexual  Homosexual   \n",
              "index                                                                     \n",
              "0           0     0               0             1         0           0  \\\n",
              "1           0     0               0             1         0           0   \n",
              "2           0     0               0             1         0           0   \n",
              "3           0     0               0             0         0           0   \n",
              "4           0     0               0             1         0           0   \n",
              "...       ...   ...             ...           ...       ...         ...   \n",
              "8202        0     0               0             1         0           0   \n",
              "8203        0     0               0             0         0           0   \n",
              "8204        0     0               0             1         0           0   \n",
              "8205        0     0               0             0         0           0   \n",
              "8206        0     0               0             1         0           0   \n",
              "\n",
              "       Asexual  Other_Orientation  Asian  Arab  Black  Indigenous_Australian   \n",
              "index                                                                          \n",
              "0            0                  0      0     0      0                      0  \\\n",
              "1            0                  0      0     0      0                      0   \n",
              "2            0                  0      0     0      0                      0   \n",
              "3            0                  1      0     0      0                      0   \n",
              "4            0                  0      0     0      1                      0   \n",
              "...        ...                ...    ...   ...    ...                    ...   \n",
              "8202         0                  0      1     0      0                      0   \n",
              "8203         1                  0      0     0      0                      0   \n",
              "8204         0                  0      0     0      0                      0   \n",
              "8205         0                  1      0     0      0                      0   \n",
              "8206         0                  0      0     0      0                      0   \n",
              "\n",
              "       Native_American  White  Other_Race  Voted  Never_married  Married   \n",
              "index                                                                      \n",
              "0                    0      0           1      0              1        0  \\\n",
              "1                    0      1           0      1              0        0   \n",
              "2                    0      1           0      0              1        0   \n",
              "3                    0      0           1      0              1        0   \n",
              "4                    0      0           0      0              1        0   \n",
              "...                ...    ...         ...    ...            ...      ...   \n",
              "8202                 0      0           0      1              1        0   \n",
              "8203                 0      0           1      0              1        0   \n",
              "8204                 0      1           0      1              0        1   \n",
              "8205                 0      1           0      0              1        0   \n",
              "8206                 0      0           1      0              1        0   \n",
              "\n",
              "       Previously_married       Age  FamilySize  Extraversion  Agreeableness   \n",
              "index                                                                          \n",
              "0                       0  0.081395    0.030075      0.214286       1.000000  \\\n",
              "1                       1  0.244186    0.015038      0.428571       0.428571   \n",
              "2                       0  0.069767    0.007519      0.357143       0.357143   \n",
              "3                       0  0.034884    0.022556      0.428571       0.714286   \n",
              "4                       0  0.058140    0.015038      0.857143       0.571429   \n",
              "...                   ...       ...         ...           ...            ...   \n",
              "8202                    0  0.104651    0.022556      0.142857       0.642857   \n",
              "8203                    0  0.058140    0.015038      0.357143       0.571429   \n",
              "8204                    0  0.383721    0.045113      0.357143       0.428571   \n",
              "8205                    0  0.011628    0.022556      0.428571       0.428571   \n",
              "8206                    0  0.034884    0.022556      0.785714       0.571429   \n",
              "\n",
              "       Conscientiousness  Emotional_Stability  Openness  \n",
              "index                                                    \n",
              "0               0.857143             0.928571  0.571429  \n",
              "1               0.857143             1.000000  0.857143  \n",
              "2               0.571429             0.928571  0.857143  \n",
              "3               0.571429             0.928571  0.571429  \n",
              "4               0.857143             0.928571  0.928571  \n",
              "...                  ...                  ...       ...  \n",
              "8202            0.142857             0.357143  0.785714  \n",
              "8203            0.714286             0.142857  0.642857  \n",
              "8204            0.857143             0.214286  0.642857  \n",
              "8205            0.214286             0.142857  0.357143  \n",
              "8206            0.714286             0.571429  0.500000  \n",
              "\n",
              "[8207 rows x 52 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f2d474e-14f7-49a3-bade-e14697c16c7e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Depression_Score</th>\n",
              "      <th>Anxiety_Score</th>\n",
              "      <th>Stress_Score</th>\n",
              "      <th>No_Degree</th>\n",
              "      <th>HighSchool</th>\n",
              "      <th>University</th>\n",
              "      <th>Graduate</th>\n",
              "      <th>Rual</th>\n",
              "      <th>Suburban</th>\n",
              "      <th>Urban</th>\n",
              "      <th>Male</th>\n",
              "      <th>Female</th>\n",
              "      <th>Other_Gender</th>\n",
              "      <th>Engnat</th>\n",
              "      <th>Right_h</th>\n",
              "      <th>Left_h</th>\n",
              "      <th>Ambidextrous</th>\n",
              "      <th>Agnostic</th>\n",
              "      <th>Atheist</th>\n",
              "      <th>Buddhist</th>\n",
              "      <th>Catholic</th>\n",
              "      <th>Mormon</th>\n",
              "      <th>Protestant</th>\n",
              "      <th>Other_Christian</th>\n",
              "      <th>Hindu</th>\n",
              "      <th>Jewish</th>\n",
              "      <th>Muslim</th>\n",
              "      <th>Sikh</th>\n",
              "      <th>Other_Religion</th>\n",
              "      <th>Heterosexual</th>\n",
              "      <th>Bisexual</th>\n",
              "      <th>Homosexual</th>\n",
              "      <th>Asexual</th>\n",
              "      <th>Other_Orientation</th>\n",
              "      <th>Asian</th>\n",
              "      <th>Arab</th>\n",
              "      <th>Black</th>\n",
              "      <th>Indigenous_Australian</th>\n",
              "      <th>Native_American</th>\n",
              "      <th>White</th>\n",
              "      <th>Other_Race</th>\n",
              "      <th>Voted</th>\n",
              "      <th>Never_married</th>\n",
              "      <th>Married</th>\n",
              "      <th>Previously_married</th>\n",
              "      <th>Age</th>\n",
              "      <th>FamilySize</th>\n",
              "      <th>Extraversion</th>\n",
              "      <th>Agreeableness</th>\n",
              "      <th>Conscientiousness</th>\n",
              "      <th>Emotional_Stability</th>\n",
              "      <th>Openness</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.081395</td>\n",
              "      <td>0.030075</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.244186</td>\n",
              "      <td>0.015038</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.069767</td>\n",
              "      <td>0.007519</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.034884</td>\n",
              "      <td>0.022556</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.058140</td>\n",
              "      <td>0.015038</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.928571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8202</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.104651</td>\n",
              "      <td>0.022556</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.785714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8203</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.058140</td>\n",
              "      <td>0.015038</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.642857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8204</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.383721</td>\n",
              "      <td>0.045113</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.642857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8205</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011628</td>\n",
              "      <td>0.022556</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.357143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8206</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.034884</td>\n",
              "      <td>0.022556</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8207 rows × 52 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f2d474e-14f7-49a3-bade-e14697c16c7e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f2d474e-14f7-49a3-bade-e14697c16c7e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f2d474e-14f7-49a3-bade-e14697c16c7e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Depression_Score    3120\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzMSY3rX1KeF"
      },
      "source": [
        "###Depression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9ySi2uJX3iZ"
      },
      "source": [
        "####Data Split for Depression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "NYWPRGeO2Aob",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28af4808-25fa-4179-f4d3-16efe7c504e6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 36.2 ms (2023-04-23T01:34:33/2023-04-23T01:34:33)</pre>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "X = Classdf[features]\n",
        "\n",
        "#Depression Model.\n",
        "D = Classdf[targets[0]]\n",
        "\n",
        "X_Claset, X_HoldClaset, D_Claset, D_HoldClaset = train_test_split(X, D, test_size=Holdout_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRwfTEhjYD21"
      },
      "source": [
        "####K Neighbors Classifier Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "jkXfcitVX9wM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "outputId": "7b6ea3a4-60c0-46e1-cc84-1aab306dc231"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre>✔️ 1 min 3 s (2023-04-23T01:38:02/2023-04-23T01:39:05)</pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy of the KNClass Model is: 42.99634591961023%\n",
            "{'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'distance'}\n",
            "                             precision    recall  f1-score   support\n",
            "\n",
            "              No Depression       0.44      0.42      0.43       509\n",
            "            Mild Depression       0.00      0.00      0.00       195\n",
            "        Moderate Depression       0.28      0.02      0.03       440\n",
            "          Severe Depression       0.00      0.00      0.00       390\n",
            "Extremely Severe Depression       0.43      0.90      0.58       929\n",
            "\n",
            "                   accuracy                           0.43      2463\n",
            "                  macro avg       0.23      0.27      0.21      2463\n",
            "               weighted avg       0.30      0.43      0.31      2463\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "KNParaClass = {\n",
        "    'n_neighbors': [75, 100, 125],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    }\n",
        "\n",
        "KNClass = KNeighborsClassifier()\n",
        "DepClaMod1 = GridSearchCV(KNClass, KNParaClass)\n",
        "DepClaMod1.fit(X_Claset, D_Claset)\n",
        "\n",
        "DModel_Acc1 = DepClaMod1.score(X_HoldClaset, D_HoldClaset)\n",
        "print(f'The Accuracy of the KNClass Model is: {DModel_Acc1*100}%')\n",
        "print(DepClaMod1.best_params_)\n",
        "\n",
        "DMod1Pred = DepClaMod1.predict(X_HoldClaset)\n",
        "print(classification_report(D_HoldClaset, DMod1Pred, target_names=DepClassNames))\n",
        "\n",
        "ConMax = confusion_matrix(D_HoldClaset, DMod1Pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=DepClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_85cpOTvYP5p"
      },
      "source": [
        "####Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYazB2REYQBt"
      },
      "outputs": [],
      "source": [
        "RandForParaClass = {\n",
        "    'n_estimators': [275, 300, 325], \n",
        "    'criterion': ['gini'], \n",
        "    'max_depth': [10,11,12], \n",
        "    'min_samples_split': [7,8,9], \n",
        "    'random_state':[randnum],\n",
        "    }\n",
        "    \n",
        "RandForClass = RandomForestClassifier()\n",
        "DepClaMod2 = GridSearchCV(RandForClass, RandForParaClass)\n",
        "DepClaMod2.fit(X_Claset, D_Claset)\n",
        "\n",
        "DModel_Acc2 = DepClaMod2.score(X_HoldClaset, D_HoldClaset)\n",
        "print(f'The Accuracy of the Random Forest Model is: {DModel_Acc2*100}%')\n",
        "print(DepClaMod2.best_params_)\n",
        "\n",
        "DMod2Pred = DepClaMod2.predict(X_HoldClaset)\n",
        "print(classification_report(D_HoldClaset, DMod2Pred, target_names=DepClassNames))\n",
        "\n",
        "ConMax = confusion_matrix(D_HoldClaset, DMod2Pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=DepClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULKzJo2mYQMF"
      },
      "source": [
        "####SVC Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pv29r2lvYQSm"
      },
      "outputs": [],
      "source": [
        "SVCClass = SVC(random_state=randnum)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Non-Polynomial SVC Model.\n",
        "SVCParaClass1 = {\n",
        "    'kernel': ['linear'],\n",
        "    'C':C,\n",
        "    }\n",
        "    \n",
        "DepClaMod3 = GridSearchCV(SVCClass, SVCParaClass1)\n",
        "DepClaMod3.fit(X_Claset, D_Claset)\n",
        "\n",
        "DModel_Acc3 = DepClaMod3.score(X_HoldClaset, D_HoldClaset)\n",
        "print(f'The Accuracy of the SVC Model is: {DModel_Acc3*100}%')\n",
        "print(DepClaMod3.best_params_)\n",
        "\n",
        "DMod3Pred = DepClaMod3.predict(X_HoldClaset)\n",
        "print(classification_report(D_HoldClaset, DMod3Pred, target_names=DepClassNames))\n",
        "\n",
        "ConMax = confusion_matrix(D_HoldClaset, DMod3Pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=DepClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NCjepfHMgWVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Polynomial SVC Model.\n",
        "SVCParaClass2 = {\n",
        "    'kernel': ['poly'],\n",
        "    'degree':[2,3,4,5,6],\n",
        "    'C':C,\n",
        "    }\n",
        "    \n",
        "DepClaMod4 = GridSearchCV(SVCClass, SVCParaClass2)\n",
        "DepClaMod4.fit(X_Claset, D_Claset)\n",
        "\n",
        "DModel_Acc4 = DepClaMod4.score(X_HoldClaset, D_HoldClaset)\n",
        "print(f'The Accuracy of the SVC Model is: {DModel_Acc4*100}%')\n",
        "print(DepClaMod4.best_params_)\n",
        "\n",
        "DMod4Pred = DepClaMod4.predict(X_HoldClaset)\n",
        "print(classification_report(D_HoldClaset, DMod4Pred, target_names=DepClassNames))\n",
        "\n",
        "ConMax = confusion_matrix(D_HoldClaset, DMod4Pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=DepClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AJK-jh1EkNs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####History Gradient Boosting Classification Model"
      ],
      "metadata": {
        "id": "GXdcfytm7ERR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HGBParaClass = {\n",
        "    'loss':['log_loss', 'auto', 'binary_crossentropy', 'categorical_crossentropy'],\n",
        "    'learning_rate':[0.1,0.3,0.5,0.7,0.9],\n",
        "    'max_iter':[75,100,150,200],\n",
        "    'max_depth':[2,5,7],\n",
        "    'random_state':[randnum],\n",
        "}\n",
        "\n",
        "HGBClass = HistGradientBoostingClassifier()\n",
        "DepClassModel5 = GridSearchCV(HGBClass, HGBParaClass)\n",
        "DepClassModel5.fit(X_Claset, D_Claset)\n",
        "\n",
        "DModel_Acc5 = DepClassModel5.score(X_HoldClaset, D_HoldClaset)\n",
        "\n",
        "print(f'The Accuracy of the HistGradientBoosting Model is: {DModel_Acc5*100}%')\n",
        "print(DepClassModel5.best_params_)\n",
        "\n",
        "DMod5Pred = DepClassModel5.predict(X_HoldClaset)\n",
        "print(classification_report(D_HoldClaset, DMod5Pred, target_names=DepClassNames))\n",
        "\n",
        "ConMax = confusion_matrix(D_HoldClaset, DMod5Pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=DepClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2VWanf8n7ERR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDsCVpWwYf6j"
      },
      "source": [
        "####Nural Network Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Kz7UEgs8an7"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "loss_function = sparse_categorical_crossentropy\n",
        "no_classes = 5\n",
        "no_epochs = 30\n",
        "optimizer = Adam()\n",
        "validation_split = 0.2\n",
        "verbosity = 1\n",
        "\n",
        "X_Train_Ten = np.asarray(X_Claset).astype(np.float32)\n",
        "D_Train_Ten = np.asarray(D_Claset).astype(np.float32)\n",
        "X_Test_Ten = np.asarray(X_HoldClaset).astype(np.float32)\n",
        "D_Test_Ten = np.asarray(D_HoldClaset).astype(np.float32)\n",
        "\n",
        "\n",
        "NNDepClass = Sequential()\n",
        "NNDepClass.add(Dense(32, activation='relu',input_shape=(None,49)))\n",
        "NNDepClass.add(Dropout(0.2))\n",
        "NNDepClass.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "NNDepClass.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "history = NNDepClass.fit(X_Train_Ten, D_Train_Ten, batch_size=batch_size, epochs=no_epochs, verbose=verbosity, validation_split=validation_split)\n",
        "\n",
        "Dscore = NNDepClass.evaluate(X_Test_Ten, D_Test_Ten, verbose=0)\n",
        "print(f'The Accuracy of the Nural Network: {Dscore[1]*100}')\n",
        "\n",
        "DMod6Pred = NNDepClass.predict(X_HoldClaset)\n",
        "print(classification_report(D_HoldClaset, DMod6Pred, target_names=DepClassNames))\n",
        "\n",
        "ConMax = confusion_matrix(D_HoldClaset, DMod6Pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=DepClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z872ZOvUYray"
      },
      "source": [
        "####Final Ensemble Methoid"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checks Which model has the greatest accuracy and throws it into an ensemble methoid to increase accuracy."
      ],
      "metadata": {
        "id": "bSXG9qKk8gbi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fJa2BXoxeQM"
      },
      "outputs": [],
      "source": [
        "ModelAccuracys = [DModel_Acc1, DModel_Acc2, DModel_Acc3, DModel_Acc4, DModel_Acc5, Dscore[1]]\n",
        "BestMod = max(ModelAccuracys)\n",
        "\n",
        "if BestMod == DModel_Acc1:\n",
        "  #The KNeighborsClassifier is the best model.\n",
        "  BestDepClassParams = DepClaMod1.best_params_\n",
        "\n",
        "  DepClaNei = BestDepClassParams['n_neighbors']\n",
        "  DepClaAlg = BestDepClassParams['algorithm']\n",
        "  DepClaWei = BestDepClassParams['weights']\n",
        "\n",
        "  FastDepClassMod = KNeighborsClassifier(n_neighbors=DepClaNei, algorithm=DepClaAlg, weights=DepClaWei, random_state=randnum)\n",
        "\n",
        "  FinalDepClaMod = BaggingClassifier(estimator=FastDepClassMod, n_estimators=50, random_state=randnum)\n",
        "  FinalDepClaMod.fit(X_Claset, D_Claset)\n",
        "\n",
        "  DClassMod_Acc = FinalDepClaMod.score(X_HoldClaset, D_HoldClaset)\n",
        "  print(f'The Accuracy of the KNeighbors Model is: {DClassMod_Acc*100}%')\n",
        "\n",
        "elif BestMod == DModel_Acc2:\n",
        "  #The Random Forest is the best model, but it's already an ensemble.\n",
        "  print(f'The Accuracy of the Random Forest Model is: {DModel_Acc2*100}%')\n",
        "\n",
        "elif BestMod == DModel_Acc3:\n",
        "  #The SVC is the best model\n",
        "  BestDepClassParams = DepClaMod3.best_params_\n",
        "\n",
        "  DepClaKer = BestDepClassParams['kernel']\n",
        "  DepClaC = BestDepClassParams['C']\n",
        "\n",
        "  FastDepClassMod = SVC(kernel=DepClaKer, C=DepClaC, random_state=randnum)\n",
        "\n",
        "  FinalDepClaMod = BaggingClassifier(estimator=FastDepClassMod, n_estimators=50, random_state=randnum)\n",
        "  FinalDepClaMod.fit(X_Claset, D_Claset)\n",
        "\n",
        "  DClassMod_Acc = FinalDepClaMod.score(X_HoldClaset, D_HoldClaset)\n",
        "  print(f'The Accuracy of the Non-Polynomial SVC Model is: {DClassMod_Acc*100}%')\n",
        "\n",
        "elif BestMod == DModel_Acc4:\n",
        "  #The SVC is the best model.\n",
        "  BestDepClassParams = DepClaMod4.best_params_\n",
        "\n",
        "  DepClaKer = BestDepClassParams['kernel']\n",
        "  DepClaDeg = BestDepClassParams['degree']\n",
        "  DepClaC = BestDepClassParams['C']\n",
        "\n",
        "  FastDepClassMod = SVC(kernel=DepClaKer, degree=DepClaDeg, C=DepClaC, random_state=randnum)\n",
        "\n",
        "  FinalDepClaMod = BaggingClassifier(estimator=FastDepClassMod, n_estimators=50, random_state=randnum)\n",
        "  FinalDepClaMod.fit(X_Claset, D_Claset)\n",
        "\n",
        "  DClassMod_Acc = FinalDepClaMod.score(X_HoldClaset, D_HoldClaset)\n",
        "  print(f'The Accuracy of the Polynomial SVC Model is: {DClassMod_Acc*100}%')\n",
        "\n",
        "elif BestMod == DModel_Acc5:\n",
        "  #The HisGradientBoosting is the best model, but it's already an ensemble.\n",
        "  print(f'The Accuracy of the HistGradientBoosting Model is: {DModel_Acc5*100}%')\n",
        "\n",
        "elif BestMod == Dscore[1]:\n",
        "  #The Nural Network is the best model\n",
        "  print(f'The Accuracy of the Nural Network Model is: {Dscore[1]*100}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkZipli1SPs"
      },
      "source": [
        "###Anxiety Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FfYWK6TY7Ij"
      },
      "source": [
        "####Data Split for Anxiety"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9772EsXRHfFR"
      },
      "outputs": [],
      "source": [
        "#Anxiety Model.\n",
        "A = Classdf[targets[1]]\n",
        "randnum = 500\n",
        "\n",
        "X_Claset, X_HoldClaset, A_Claset, A_HoldClaset = train_test_split(X, A, test_size=Holdout_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BEePMb3ZUrO"
      },
      "source": [
        "####K Neighbors Classifier Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZCDQ9iFZUxw"
      },
      "outputs": [],
      "source": [
        "KNClassPara = {\n",
        "    'n_neighbors': [75, 100, 125], \n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
        "    'weights': ['uniform', 'distance'],\n",
        "    }\n",
        "    \n",
        "KNClass = KNeighborsClassifier()\n",
        "AnxCalModel1 = GridSearchCV(KNClass, KNClassPara)\n",
        "AnxCalModel1.fit(X_Claset, A_Claset)\n",
        "\n",
        "AModel_Acc1 = AnxCalModel1.score(X_HoldClaset, A_HoldClaset)\n",
        "print(f'The Accuracy of the KNClass Model is: {AModel_Acc1*100}%')\n",
        "print(AnxCalModel1.best_params_)\n",
        "\n",
        "AMod1Pred = AnxCalModel1.predict(X_HoldClaset)\n",
        "print(classification_report(A_HoldClaset, AMod1Pred, target_names=AnxClassNames))\n",
        "\n",
        "ConMax = confusion_matrix(A_HoldClaset, AMod1Pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=AnxClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfoOEjx2ZVEE"
      },
      "source": [
        "####Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUuZIWfbZVJq"
      },
      "outputs": [],
      "source": [
        "RandForClaPar = {\n",
        "    'n_estimators': [175, 200, 225], \n",
        "    'criterion': ['gini'], \n",
        "    'max_depth': [20,23,25], \n",
        "    'min_samples_split': [7,8,9],\n",
        "    'random_state':[randnum],\n",
        "    }\n",
        "    \n",
        "RandForClassMod = RandomForestClassifier()\n",
        "AnxCalModel2 = GridSearchCV(RandForClassMod, RandForClaPar)\n",
        "AnxCalModel2.fit(X_Claset, A_Claset)\n",
        "\n",
        "AModel_Acc2 = AnxCalModel2.score(X_HoldClaset, A_HoldClaset)\n",
        "print(f'The Accuracy of the Random Forest Model is: {AModel_Acc2*100}%')\n",
        "print(AnxCalModel2.best_params_)\n",
        "\n",
        "AMod2Pred = AnxCalModel2.predict(X_HoldClaset)\n",
        "print(classification_report(A_HoldClaset, AMod2Pred))\n",
        "\n",
        "ConMax = confusion_matrix(A_HoldClaset, AMod2Pred, labels=AnxClassNames)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=AnxClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4aZ1jS-ZVQC"
      },
      "source": [
        "####SVC Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SVCClass = SVC(random_state=randnum)"
      ],
      "metadata": {
        "id": "NrVIvOKsm39i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoAVyJ8DZVWT"
      },
      "outputs": [],
      "source": [
        "#Non-Polynomial SVC Model.\n",
        "SVCParaClass1 = {\n",
        "    'kernel': ['linear'],\n",
        "    'C':C,\n",
        "    }\n",
        "\n",
        "SVCClass = SVC()\n",
        "AnxCalModel3 = GridSearchCV(SVCClass, SVCParaClass1)\n",
        "AnxCalModel3.fit(X_Claset, A_Claset)\n",
        "\n",
        "AModel_Acc3 = AnxCalModel3.score(X_HoldClaset, A_HoldClaset)\n",
        "print(f'The Accuracy of the SVC Model is: {AModel_Acc3*100}%')\n",
        "print(AnxCalModel3.best_params_)\n",
        "\n",
        "AMod3Pred = AnxCalModel3.predict(X_HoldClaset)\n",
        "print(classification_report(A_HoldClaset, AMod3Pred, target_names=AnxClassNames))\n",
        "\n",
        "ConMax = confusion_matrix(A_HoldClaset, AMod3Pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=AnxClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Polynomial SVC Model.\n",
        "SVCParaClass2 = {\n",
        "    'kernel': ['poly'],\n",
        "    'degree':[2,3],\n",
        "    'C':C,\n",
        "    }\n",
        "\n",
        "SVCClass = SVC()\n",
        "AnxCalModel4 = GridSearchCV(SVCClass, SVCParaClass2)\n",
        "AnxCalModel4.fit(X_Claset, A_Claset)\n",
        "\n",
        "AModel_Acc4 = AnxCalModel4.score(X_HoldClaset, A_HoldClaset)\n",
        "print(f'The Accuracy of the SVC Model is: {AModel_Acc4*100}%')\n",
        "print(AnxCalModel4.best_params_)\n",
        "\n",
        "AMod4Pred = AnxCalModel4.predict(X_HoldClaset)\n",
        "print(classification_report(A_HoldClaset, AMod4Pred, target_names=AnxClassNames))\n",
        "\n",
        "ConMax = confusion_matrix(A_HoldClaset, AMod4Pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=AnxClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "94_j1iJ_nHBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####History Gradient Boosting Classification Model"
      ],
      "metadata": {
        "id": "Gh91gq7_8hKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HGBParaClass = {\n",
        "    'loss':['log_loss', 'auto', 'binary_crossentropy', 'categorical_crossentropy'],\n",
        "    'learning_rate':[0.1,0.3,0.5,0.7,0.9],\n",
        "    'max_iter':[75,100,150,200],\n",
        "    'max_depth':[2,5,7],\n",
        "    'random_state':[randnum],\n",
        "}\n",
        "\n",
        "HGBClass = HistGradientBoostingClassifier()\n",
        "AnxClassModel5 = GridSearchCV(HGBClass, HGBParaClass)\n",
        "AnxClassModel5.fit(X_Claset, A_Claset)\n",
        "\n",
        "AModel_Acc5 = AnxClassModel5.score(X_HoldClaset, A_HoldClaset)\n",
        "\n",
        "print(f'The Accuracy of the HistGradientBoosting Model is: {AModel_Acc5*100}%')\n",
        "print(AnxClassModel5.best_params_)\n",
        "\n",
        "AMod5Pred = AnxClassModel5.predict(X_HoldClaset)\n",
        "print(classification_report(A_HoldClaset, AMod5Pred, target_names=AnxClassNames))\n",
        "\n",
        "ConMax = confusion_matrix(A_HoldClaset, AMod5Pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=AnxClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_f35mVNf8hKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpBKbvEPZvDc"
      },
      "source": [
        "####Nural Network Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12Pf1fTu1epw"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "loss_function = sparse_categorical_crossentropy\n",
        "no_classes = 5\n",
        "no_epochs = 30\n",
        "optimizer = Adam()\n",
        "validation_split = 0.2\n",
        "verbosity = 1\n",
        "\n",
        "X_Train_Ten = np.asarray(X_Claset).astype(np.float32)\n",
        "A_Train_Ten = np.asarray(A_Claset).astype(np.float32)\n",
        "X_Test_Ten = np.asarray(X_HoldClaset).astype(np.float32)\n",
        "A_Test_Ten = np.asarray(A_HoldClaset).astype(np.float32)\n",
        "\n",
        "\n",
        "NNAnxClassMod = Sequential()\n",
        "NNAnxClassMod.add(Dense(64, activation='relu',input_shape=(None,49)))\n",
        "NNAnxClassMod.add(Dropout(0.2))\n",
        "NNAnxClassMod.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "NNAnxClassMod.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "history = NNAnxClassMod.fit(X_Train_Ten, A_Train_Ten, batch_size=batch_size, epochs=no_epochs, verbose=verbosity, validation_split=validation_split)\n",
        "\n",
        "Ascore = NNAnxClassMod.evaluate(X_Test_Ten, A_Test_Ten, verbose=0)\n",
        "print(f'The Accuracy of the Nural Network: {Ascore[1]*100}')\n",
        "\n",
        "AMod6Pred = NNAnxClassMod.predict(X_HoldClaset)\n",
        "print(classification_report(A_HoldClaset, AMod6Pred, target_names=AnxClassNames))\n",
        "\n",
        "ConMax = confusion_matrix(A_HoldClaset, AMod6Pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=AnxClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCeBf2-tZzy1"
      },
      "source": [
        "####Final Ensamble Methoid"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checks Which model has the greatest accuracy and throws it into an ensemble methoid to increase accuracy."
      ],
      "metadata": {
        "id": "rwsoIEk1_D_1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cckKeil31eiK"
      },
      "outputs": [],
      "source": [
        "ModelAccuracys = [AModel_Acc1, AModel_Acc2, AModel_Acc3, AModel_Acc4, AModel_Acc5, Ascore[1]]\n",
        "BestMod = max(ModelAccuracys)\n",
        "\n",
        "if BestMod == AModel_Acc1:\n",
        "  #The KNeighborsClassifier is the best model.\n",
        "  BestAnxClassParams = AnxCalModel1.best_params_\n",
        "\n",
        "  AnxClaNei = BestAnxClassParams['n_neighbors']\n",
        "  AnxClaAlg = BestAnxClassParams['algorithm']\n",
        "  AnxClaWei = BestAnxClassParams['weights']\n",
        "\n",
        "  FastAnxClassMod = KNeighborsClassifier(n_neighbors=AnxClaNei, algorithm=AnxClaAlg, weights=AnxClaWei, random_state=randnum)\n",
        "\n",
        "  FinalAnxClaMod = BaggingClassifier(estimator=FastAnxClassMod, n_estimators=50, random_state=randnum)\n",
        "  FinalAnxClaMod.fit(X_Claset, A_Claset)\n",
        "\n",
        "  AClassMod_Acc = FinalAnxClaMod.score(X_HoldClaset, A_HoldClaset)\n",
        "  print(f'The Accuracy of the KNeighbors Model is: {AClassMod_Acc*100}%')\n",
        "\n",
        "elif BestMod == AModel_Acc2:\n",
        "  #The Random Forest is the best model, but it's already an ensemble.\n",
        "  print(f'The Accuracy of the Random Forest Model is: {AModel_Acc2*100}%')\n",
        "\n",
        "elif BestMod == AModel_Acc3:\n",
        "  #The SVC is the best model.\n",
        "  BestAnxClassParams = AnxCalModel3.best_params_\n",
        "\n",
        "  AnxClaKer = BestAnxClassParams['kernel']\n",
        "  AnxClaC = BestAnxClassParams['C']\n",
        "\n",
        "  FastAnxClassMod = SVC(kernel=AnxClaKer, C=AnxClaC, random_state=randnum)\n",
        "\n",
        "  FinalAnxClaMod = BaggingClassifier(estimator=FastAnxClassMod, n_estimators=50, random_state=randnum)\n",
        "  FinalAnxClaMod.fit(X_Claset, A_Claset)\n",
        "\n",
        "  AClassMod_Acc = FinalAnxClaMod.score(X_HoldClaset, A_HoldClaset)\n",
        "  print(f'The Accuracy of the Non-Polynomial SVC Model is: {AClassMod_Acc*100}%')\n",
        "\n",
        "elif BestMod == AModel_Acc4:\n",
        "  #The SVC is the best model.\n",
        "  BestAnxClassParams = AnxCalModel4.best_params_\n",
        "\n",
        "  AnxClaKer = BestAnxClassParams['kernel']\n",
        "  AnxClaDeg = BestAnxClassParams['degree']\n",
        "  AnxClaC = BestAnxClassParams['C']\n",
        "\n",
        "  FastAnxClassMod = SVC(kernel=AnxClaKer, degree=AnxClaDeg, C=AnxClaC, random_state=randnum)\n",
        "\n",
        "  FinalAnxClaMod = BaggingClassifier(estimator=FastAnxClassMod, n_estimators=50, random_state=randnum)\n",
        "  FinalAnxClaMod.fit(X_Claset, A_Claset)\n",
        "\n",
        "  AClassMod_Acc = FinalAnxClaMod.score(X_HoldClaset, A_HoldClaset)\n",
        "  print(f'The Accuracy of the Polynomial SVC Model is: {AClassMod_Acc*100}%')\n",
        "\n",
        "elif BestMod == AModel_Acc5:\n",
        "  #The HistGradientBoosting is the best model, but it's already an ensemble.\n",
        "  print(f'The Accuracy of the HistGradientBoosting Model is: {AModel_Acc5*100}%')\n",
        "\n",
        "elif BestMod == Ascore[1]:\n",
        "  #The Nural Network is the best model.\n",
        "  print(f'The Accuracy of the Nural Network Model is: {Ascore[1]*100}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emdL0Gl31Vqo"
      },
      "source": [
        "###Stress Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tIhIwb6aFX3"
      },
      "source": [
        "####Data Split for Stress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TavXFjBfHe-B"
      },
      "outputs": [],
      "source": [
        "S = Classdf[targets[2]]\n",
        "\n",
        "X_Claset, X_HoldClaset, S_Claset, S_HoldClaset = train_test_split(X, S, test_size=Holdout_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZxnkHoNZ_T7"
      },
      "source": [
        "####K Neighbors Classifier Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbXbMnkpZ_l7"
      },
      "outputs": [],
      "source": [
        "KNClassPara = {\n",
        "    'n_neighbors': [15, 20, 100, 300], \n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
        "    'weights': ['uniform', 'distance'],\n",
        "    }\n",
        "    \n",
        "KNClass = KNeighborsClassifier()\n",
        "StrsClassModel1 = GridSearchCV(KNClass, KNClassPara)\n",
        "StrsClassModel1.fit(X_Claset, S_Claset)\n",
        "\n",
        "SModel_Acc1 = StrsClassModel1.score(X_HoldClaset, S_HoldClaset)\n",
        "print(f'The Accuracy of the KNClass Model is: {SModel_Acc1*100}%')\n",
        "print(StrsClassModel1.best_params_)\n",
        "\n",
        "SMod1Pred = StrsClassModel1.predict(X_HoldClaset)\n",
        "print(classification_report(S_HoldClaset, SMod1Pred, target_names=StsClassNames))\n",
        "\n",
        "ConMax = confusion_matrix(S_HoldClaset, SMod1Pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=StsClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTB5VansaBHE"
      },
      "source": [
        "####Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKvDZGAMaBwe"
      },
      "outputs": [],
      "source": [
        "RandForClassPara = {\n",
        "    'n_estimators': [100, 150, 200], \n",
        "    'criterion': ['gini', 'entropy', 'log_loss'], \n",
        "    'max_depth': [12,15,20], \n",
        "    'min_samples_split': [5,6,7,8], \n",
        "    'random_state':[randnum],\n",
        "    }\n",
        "    \n",
        "RandForClass = RandomForestClassifier()\n",
        "StrsClassModel2 = GridSearchCV(RandForClass, RandForClassPara)\n",
        "StrsClassModel2.fit(X_Claset, S_Claset)\n",
        "\n",
        "SModel_Acc2 = StrsClassModel2.score(X_HoldClaset, S_HoldClaset)\n",
        "print(f'The Accuracy of the Random Forest Model is: {SModel_Acc2*100}%')\n",
        "print(StrsClassModel2.best_params_)\n",
        "\n",
        "SMod2Pred = StrsClassModel2.predict(X_HoldClaset)\n",
        "print(classification_report(S_HoldClaset, SMod2Pred, target_names=StsClassNames))\n",
        "\n",
        "ConMax = confusion_matrix(S_HoldClaset, SMod2Pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=StsClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma_1ji4OaDUQ"
      },
      "source": [
        "####SVC Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYp1NPyDaDaL"
      },
      "outputs": [],
      "source": [
        "SVCClass = SVC(random_state=randnum)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Non-Polynomial SVC Model.\n",
        "SVCParaClass1 = {\n",
        "    'kernel': ['linear'],\n",
        "    'C':C,\n",
        "    }\n",
        "\n",
        "StrsClassModel3 = GridSearchCV(SVCClass, SVCParaClass1)\n",
        "StrsClassModel3.fit(X_Claset, S_Claset)\n",
        "\n",
        "SModel_Acc3 = StrsClassModel3.score(X_HoldClaset, S_HoldClaset)\n",
        "print(f'The Accuracy of the SVC Model is: {SModel_Acc3*100}%')\n",
        "print(StrsClassModel3.best_params_)\n",
        "\n",
        "SMod3Pred = StrsClassModel3.predict(X_HoldClaset)\n",
        "print(classification_report(S_HoldClaset, SMod3Pred, target_names=StsClassNames))\n",
        "\n",
        "ConMax = confusion_matrix(S_HoldClaset, SMod3Pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=StsClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c-v8_ZFfsmMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Polynomial SVC Model.\n",
        "SVCParaClass2 = {\n",
        "    'kernel': ['poly'],\n",
        "    'degree':[2,3,4,5,6],\n",
        "    'C':C,\n",
        "    }\n",
        "\n",
        "StrsClassModel4 = GridSearchCV(SVCClass, SVCParaClass2)\n",
        "StrsClassModel4.fit(X_Claset, S_Claset)\n",
        "\n",
        "SModel_Acc4 = StrsClassModel4.score(X_HoldClaset, S_HoldClaset)\n",
        "print(f'The Accuracy of the SVC Model is: {SModel_Acc4*100}%')\n",
        "print(StrsClassModel4.best_params_)\n",
        "\n",
        "SMod4Pred = StrsClassModel4.predict(X_HoldClaset)\n",
        "print(classification_report(S_HoldClaset, SMod4Pred, target_names=StsClassNames))\n",
        "\n",
        "ConMax = confusion_matrix(S_HoldClaset, SMod4Pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=StsClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OFejHq5CsmAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####History Gradient Boosting Classification Model"
      ],
      "metadata": {
        "id": "PObxcmC-9jFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HGBParaClass = {\n",
        "    'loss':['log_loss', 'auto', 'binary_crossentropy', 'categorical_crossentropy'],\n",
        "    'learning_rate':[0.1,0.3,0.5,0.7,0.9],\n",
        "    'max_iter':[75,100,150,200],\n",
        "    'max_depth':[2,5,7],\n",
        "    'random_state':[randnum],\n",
        "}\n",
        "\n",
        "HGBClass = HistGradientBoostingClassifier()\n",
        "StsClassModel5 = GridSearchCV(HGBClass, HGBParaClass)\n",
        "StsClassModel5.fit(X_Claset, S_Claset)\n",
        "\n",
        "SModel_Acc5 = StsClassModel5.score(X_HoldClaset, S_HoldClaset)\n",
        "\n",
        "print(f'The Accuracy of the HistGradientBoosting Model is: {SModel_Acc5*100}%')\n",
        "print(StsClassModel5.best_params_)\n",
        "\n",
        "SMod5Pred = StsClassModel5.predict(X_HoldClaset)\n",
        "print(classification_report(S_HoldClaset, SMod5Pred, target_names=StsClassNames))\n",
        "\n",
        "ConMax = confusion_matrix(S_HoldClaset, SMod5Pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=StsClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MVwiOMhM9jFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tVvvKfDbyRq"
      },
      "source": [
        "####Nural Network Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Fyrco7d1fJC"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "loss_function = sparse_categorical_crossentropy\n",
        "no_classes = 5\n",
        "no_epochs = 30\n",
        "optimizer = Adam()\n",
        "validation_split = 0.2\n",
        "verbosity = 1\n",
        "\n",
        "X_Train_Ten = np.asarray(X_Claset).astype(np.float32)\n",
        "S_Train_Ten = np.asarray(S_Claset).astype(np.float32)\n",
        "X_Test_Ten = np.asarray(X_HoldClaset).astype(np.float32)\n",
        "S_Test_Ten = np.asarray(S_HoldClaset).astype(np.float32)\n",
        "\n",
        "\n",
        "NNStsClassMod = Sequential()\n",
        "NNStsClassMod.add(Dense(32, activation='relu',input_shape=(None,49)))\n",
        "NNStsClassMod.add(Dropout(0.2))\n",
        "NNStsClassMod.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "NNStsClassMod.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "history = NNStsClassMod.fit(X_Train_Ten, S_Train_Ten, batch_size=batch_size, epochs=no_epochs, verbose=verbosity, validation_split=validation_split)\n",
        "\n",
        "Sscore = NNStsClassMod.evaluate(X_Test_Ten, S_Test_Ten, verbose=0)\n",
        "print(f'The Accuracy of the Nural Network: {Sscore[1]*100}')\n",
        "\n",
        "SMod6Pred = NNStsClassMod.predict(X_HoldClaset)\n",
        "print(classification_report(S_HoldClaset, SMod6Pred, target_names=StsClassNames))\n",
        "\n",
        "ConMax = confusion_matrix(S_HoldClaset, SMod6Pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=ConMax, display_labels=StsClassNames)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LozrfKKbypZ"
      },
      "source": [
        "####Final Ensemble Methoid"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checks Which model has the greatest accuracy and throws it into an ensemble methoid to increase accuracy."
      ],
      "metadata": {
        "id": "uKfxIRgL_4nb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2cYWls11fGq"
      },
      "outputs": [],
      "source": [
        "ModelAccuracys = [SModel_Acc1, SModel_Acc2, SModel_Acc3, SModel_Acc4, SModel_Acc5, Sscore[1]]\n",
        "BestMod = max(ModelAccuracys)\n",
        "\n",
        "if BestMod == SModel_Acc1:\n",
        "  #The KNeighborsClassifier is the best model.\n",
        "  BestStsClassParams = StrsClassModel1.best_params_\n",
        "\n",
        "  StsClaNei = BestStsClassParams['n_neighbors']\n",
        "  StsClaAlg = BestStsClassParams['algorithm']\n",
        "  StsClaWei = BestStsClassParams['weights']\n",
        "\n",
        "  FastStsClassMod = KNeighborsClassifier(n_neighbors=StsClaNei, algorithm=StsClaAlg, weights=StsClaWei, random_state=randnum)\n",
        "\n",
        "  FinalStsClaMod = BaggingClassifier(estimator=FastStsClassMod, n_estimators=50, random_state=randnum)\n",
        "  FinalStsClaMod.fit(X_Claset, S_Calset)\n",
        "\n",
        "  SClassMod_Acc = FinalStsClaMod.score(X_HoldClaset, S_HoldClaset)\n",
        "  print(f'The Accuracy of the KNeighbors Model is: {SClassMod_Acc*100}%')\n",
        "\n",
        "elif BestMod == SModel_Acc2:\n",
        "  #The Random Forest is the best model, but it's already an ensemble.\n",
        "  print(f'The Accuracy of the Random Forest Model is: {SModel_Acc2*100}%')\n",
        "\n",
        "elif BestMod == SModel_Acc3:\n",
        "  #The SVC is the best model.\n",
        "  BestStsClassParams = StrsClassModel3.best_params_\n",
        "\n",
        "  StsClaKer = BestStsClassParams['kernel']\n",
        "  StsClaC = BestStsClassParams['C']\n",
        "\n",
        "  FastStsClassMod = SVC(kernel=StsClaKer, C=StsClaC, random_state=randnum)\n",
        "\n",
        "  FinalStsClaMod = BaggingClassifier(estimator=FastStsClassMod, n_estimators=50, random_state=randnum)\n",
        "  FinalStsClaMod.fit(X_Claset, S_Calset)\n",
        "\n",
        "  SClassMod_Acc = FinalStsClaMod.score(X_HoldClaset, S_HoldClaset)\n",
        "  print(f'The Accuracy of the Non-Polynomial SVC Model is: {SClassMod_Acc*100}%')\n",
        "\n",
        "elif BestMod == SModel_Acc4:\n",
        "  #The Polynomial SVC is the best model.\n",
        "  BestStsClassParams = StrsClassModel4.best_params_\n",
        "\n",
        "  StsClaKer = BestStsClassParams['kernel']\n",
        "  StsClaDeg = BestStsClassParams['degree']\n",
        "  StsClaC = BestStsClassParams['C']\n",
        "\n",
        "  FastStsClassMod = SVC(kernel=StsClaKer, degree=StsClaDeg, C=StsClaC, random_state=randnum)\n",
        "\n",
        "  FinalStsClaMod = BaggingClassifier(estimator=FastStsClassMod, n_estimators=50, random_state=randnum)\n",
        "  FinalStsClaMod.fit(X_Claset, S_Calset)\n",
        "\n",
        "  SClassMod_Acc = FinalStsClaMod.score(X_HoldClaset, S_HoldClaset)\n",
        "  print(f'The Accuracy of the Polynomial SVC Model is: {SClassMod_Acc*100}%')\n",
        "\n",
        "elif BestMod == SModel_Acc5:\n",
        "  #The HisGradientBoosting is the best model, but it's already an ensemble.\n",
        "  print(f'The Accuracy of the HistGradientBoosting Model is: {SModel_Acc5*100}%')\n",
        "\n",
        "elif BestMod == Sscore[1]:\n",
        "  #The MLP is the best model.\n",
        "  print(f'The Accuracy of the MLP Model is: {Sscore[1]*100}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion"
      ],
      "metadata": {
        "id": "63RHuvMvNaxe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yGPZMlPgNkWO"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4khyxgT0P3p4",
        "1s8-xWnQULif",
        "9pp71514hoxZ",
        "PB6OhOPkvWI9",
        "UY02y715otK0",
        "_jXaRgKgokQI",
        "lOplAYr41FQ3",
        "63RHuvMvNaxe"
      ],
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "10hfp4PoZEjrwMoAw5B1e4oKKVU0faOXS",
      "authorship_tag": "ABX9TyNZwAZSSEd6hspaST/qzcuH",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}